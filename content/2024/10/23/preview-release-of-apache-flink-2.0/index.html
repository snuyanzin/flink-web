
<!DOCTYPE html>
<html lang="en" dir=ZgotmplZ>

<head>
  


<link rel="stylesheet" href="/bootstrap/css/bootstrap.min.css">
<script src="/bootstrap/js/bootstrap.bundle.min.js"></script>
<link rel="stylesheet" type="text/css" href="/font-awesome/css/font-awesome.min.css">
<script src="/js/anchor.min.js"></script>
<script src="/js/flink.js"></script>
<link rel="canonical" href="https://flink.apache.org/2024/10/23/preview-release-of-apache-flink-2.0/">

  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="The Apache Flink community is actively preparing Flink 2.0, the first major release since Flink 1.0 launched 8 years ago. As a significant milestone, Flink 2.0 is set to introduce numerous innovative features and improvements, along with some compatibility-breaking changes. To facilitate early adaptation to these changes for our users and partner projects (e.g., connectors), and to offer a sneak peek into the exciting new features while gathering feedback, we are now providing a preview release of Flink 2.">
<meta name="theme-color" content="#FFFFFF"><meta property="og:title" content="Preview Release of Apache Flink 2.0" />
<meta property="og:description" content="The Apache Flink community is actively preparing Flink 2.0, the first major release since Flink 1.0 launched 8 years ago. As a significant milestone, Flink 2.0 is set to introduce numerous innovative features and improvements, along with some compatibility-breaking changes. To facilitate early adaptation to these changes for our users and partner projects (e.g., connectors), and to offer a sneak peek into the exciting new features while gathering feedback, we are now providing a preview release of Flink 2." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://flink.apache.org/2024/10/23/preview-release-of-apache-flink-2.0/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-10-23T08:00:00+00:00" />
<meta property="article:modified_time" content="2024-10-23T08:00:00+00:00" />
<title>Preview Release of Apache Flink 2.0 | Apache Flink</title>
<link rel="manifest" href="/manifest.json">
<link rel="icon" href="/favicon.png" type="image/x-icon">
<link rel="stylesheet" href="/book.min.22eceb4d17baa9cdc0f57345edd6f215a40474022dfee39b63befb5fb3c596b5.css" integrity="sha256-IuzrTRe6qc3A9XNF7dbyFaQEdAIt/uObY777X7PFlrU=">
<script defer src="/en.search.min.8b577e9d160e1b929649956cddbaaf7466a08888cdb74e99e2716b92252f5b9e.js" integrity="sha256-i1d&#43;nRYOG5KWSZVs3bqvdGagiIjNt06Z4nFrkiUvW54="></script>
<!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->

  <meta name="generator" content="Hugo 0.124.1">

    
    <script>
      var _paq = window._paq = window._paq || [];
       
       
      _paq.push(['disableCookies']);
       
      _paq.push(["setDomains", ["*.flink.apache.org","*.nightlies.apache.org/flink"]]);
      _paq.push(['trackPageView']);
      _paq.push(['enableLinkTracking']);
      (function() {
        var u="//analytics.apache.org/";
        _paq.push(['setTrackerUrl', u+'matomo.php']);
        _paq.push(['setSiteId', '1']);
        var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
        g.async=true; g.src=u+'matomo.js'; s.parentNode.insertBefore(g,s);
      })();
    </script>
    
</head>

<body dir=ZgotmplZ>
  


<header>
  <nav class="navbar navbar-expand-xl">
    <div class="container-fluid">
      <a class="navbar-brand" href="/">
        <img src="/img/logo/png/100/flink_squirrel_100_color.png" alt="Apache Flink" height="47" width="47" class="d-inline-block align-text-middle">
        <span>Apache Flink</span>
      </a>
      <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
          <i class="fa fa-bars navbar-toggler-icon"></i>
      </button>
      <div class="collapse navbar-collapse" id="navbarSupportedContent">
        <ul class="navbar-nav">
          





    
      
  
    <li class="nav-item dropdown">
      <a class="nav-link dropdown-toggle" href="#" role="button" data-bs-toggle="dropdown" aria-expanded="false">About</a>
      <ul class="dropdown-menu">
        
          <li>
            
  
    <a class="dropdown-item" href="/what-is-flink/flink-architecture/">Architecture</a>
  

          </li>
        
          <li>
            
  
    <a class="dropdown-item" href="/what-is-flink/flink-applications/">Applications</a>
  

          </li>
        
          <li>
            
  
    <a class="dropdown-item" href="/what-is-flink/flink-operations/">Operations</a>
  

          </li>
        
          <li>
            
  
    <a class="dropdown-item" href="/what-is-flink/use-cases/">Use Cases</a>
  

          </li>
        
          <li>
            
  
    <a class="dropdown-item" href="/what-is-flink/powered-by/">Powered By</a>
  

          </li>
        
          <li>
            
  
    <a class="dropdown-item" href="/what-is-flink/roadmap/">Roadmap</a>
  

          </li>
        
          <li>
            
  
    <a class="dropdown-item" href="/what-is-flink/community/">Community & Project Info</a>
  

          </li>
        
          <li>
            
  
    <a class="dropdown-item" href="/what-is-flink/security/">Security</a>
  

          </li>
        
          <li>
            
  
    <a class="dropdown-item" href="/what-is-flink/special-thanks/">Special Thanks</a>
  

          </li>
        
      </ul>
    </li>
  

    
      
  
    <li class="nav-item dropdown">
      <a class="nav-link dropdown-toggle" href="#" role="button" data-bs-toggle="dropdown" aria-expanded="false">Getting Started</a>
      <ul class="dropdown-menu">
        
          <li>
            
  
    <a class="dropdown-item" href="https://nightlies.apache.org/flink/flink-docs-stable/docs/try-flink/local_installation/">With Flink<i class="link fa fa-external-link title" aria-hidden="true"></i>
    </a>
  

          </li>
        
          <li>
            
  
    <a class="dropdown-item" href="https://nightlies.apache.org/flink/flink-kubernetes-operator-docs-stable/docs/try-flink-kubernetes-operator/quick-start/">With Flink Kubernetes Operator<i class="link fa fa-external-link title" aria-hidden="true"></i>
    </a>
  

          </li>
        
          <li>
            
  
    <a class="dropdown-item" href="https://nightlies.apache.org/flink/flink-cdc-docs-stable/docs/get-started/introduction/">With Flink CDC<i class="link fa fa-external-link title" aria-hidden="true"></i>
    </a>
  

          </li>
        
          <li>
            
  
    <a class="dropdown-item" href="https://nightlies.apache.org/flink/flink-ml-docs-stable/docs/try-flink-ml/quick-start/">With Flink ML<i class="link fa fa-external-link title" aria-hidden="true"></i>
    </a>
  

          </li>
        
          <li>
            
  
    <a class="dropdown-item" href="https://nightlies.apache.org/flink/flink-statefun-docs-stable/getting-started/project-setup.html">With Flink Stateful Functions<i class="link fa fa-external-link title" aria-hidden="true"></i>
    </a>
  

          </li>
        
          <li>
            
  
    <a class="dropdown-item" href="https://nightlies.apache.org/flink/flink-docs-stable/docs/learn-flink/overview/">Training Course<i class="link fa fa-external-link title" aria-hidden="true"></i>
    </a>
  

          </li>
        
      </ul>
    </li>
  

    
      
  
    <li class="nav-item dropdown">
      <a class="nav-link dropdown-toggle" href="#" role="button" data-bs-toggle="dropdown" aria-expanded="false">Documentation</a>
      <ul class="dropdown-menu">
        
          <li>
            
  
    <a class="dropdown-item" href="https://nightlies.apache.org/flink/flink-docs-stable/">Flink 1.20 (stable)<i class="link fa fa-external-link title" aria-hidden="true"></i>
    </a>
  

          </li>
        
          <li>
            
  
    <a class="dropdown-item" href="https://nightlies.apache.org/flink/flink-docs-release-2.0-preview1/">Flink 2.0 (preview)<i class="link fa fa-external-link title" aria-hidden="true"></i>
    </a>
  

          </li>
        
          <li>
            
  
    <a class="dropdown-item" href="https://nightlies.apache.org/flink/flink-docs-master/">Flink Master (snapshot)<i class="link fa fa-external-link title" aria-hidden="true"></i>
    </a>
  

          </li>
        
          <li>
            
  
    <a class="dropdown-item" href="https://nightlies.apache.org/flink/flink-kubernetes-operator-docs-stable/">Kubernetes Operator 1.10 (latest)<i class="link fa fa-external-link title" aria-hidden="true"></i>
    </a>
  

          </li>
        
          <li>
            
  
    <a class="dropdown-item" href="https://nightlies.apache.org/flink/flink-kubernetes-operator-docs-main">Kubernetes Operator Main (snapshot)<i class="link fa fa-external-link title" aria-hidden="true"></i>
    </a>
  

          </li>
        
          <li>
            
  
    <a class="dropdown-item" href="https://nightlies.apache.org/flink/flink-cdc-docs-stable">CDC 3.2 (stable)<i class="link fa fa-external-link title" aria-hidden="true"></i>
    </a>
  

          </li>
        
          <li>
            
  
    <a class="dropdown-item" href="https://nightlies.apache.org/flink/flink-cdc-docs-master">CDC Master (snapshot)<i class="link fa fa-external-link title" aria-hidden="true"></i>
    </a>
  

          </li>
        
          <li>
            
  
    <a class="dropdown-item" href="https://nightlies.apache.org/flink/flink-ml-docs-stable/">ML 2.3 (stable)<i class="link fa fa-external-link title" aria-hidden="true"></i>
    </a>
  

          </li>
        
          <li>
            
  
    <a class="dropdown-item" href="https://nightlies.apache.org/flink/flink-ml-docs-master">ML Master (snapshot)<i class="link fa fa-external-link title" aria-hidden="true"></i>
    </a>
  

          </li>
        
          <li>
            
  
    <a class="dropdown-item" href="https://nightlies.apache.org/flink/flink-statefun-docs-stable/">Stateful Functions 3.3 (stable)<i class="link fa fa-external-link title" aria-hidden="true"></i>
    </a>
  

          </li>
        
          <li>
            
  
    <a class="dropdown-item" href="https://nightlies.apache.org/flink/flink-statefun-docs-master">Stateful Functions Master (snapshot)<i class="link fa fa-external-link title" aria-hidden="true"></i>
    </a>
  

          </li>
        
      </ul>
    </li>
  

    
      
  
    <li class="nav-item dropdown">
      <a class="nav-link dropdown-toggle" href="#" role="button" data-bs-toggle="dropdown" aria-expanded="false">How to Contribute</a>
      <ul class="dropdown-menu">
        
          <li>
            
  
    <a class="dropdown-item" href="/how-to-contribute/overview/">Overview</a>
  

          </li>
        
          <li>
            
  
    <a class="dropdown-item" href="/how-to-contribute/contribute-code/">Contribute Code</a>
  

          </li>
        
          <li>
            
  
    <a class="dropdown-item" href="/how-to-contribute/reviewing-prs/">Review Pull Requests</a>
  

          </li>
        
          <li>
            
  
    <a class="dropdown-item" href="/how-to-contribute/code-style-and-quality-preamble/">Code Style and Quality Guide</a>
  

          </li>
        
          <li>
            
  
    <a class="dropdown-item" href="/how-to-contribute/contribute-documentation/">Contribute Documentation</a>
  

          </li>
        
          <li>
            
  
    <a class="dropdown-item" href="/how-to-contribute/documentation-style-guide/">Documentation Style Guide</a>
  

          </li>
        
          <li>
            
  
    <a class="dropdown-item" href="/how-to-contribute/improve-website/">Contribute to the Website</a>
  

          </li>
        
          <li>
            
  
    <a class="dropdown-item" href="/how-to-contribute/getting-help/">Getting Help</a>
  

          </li>
        
      </ul>
    </li>
  

    


    
      
  
    <li class="nav-item">
      
  
    <a class="nav-link" href="/posts/">Flink Blog</a>
  

    </li>
  

    
      
  
    <li class="nav-item">
      
  
    <a class="nav-link" href="/downloads/">Downloads</a>
  

    </li>
  

    


    









        </ul>
        <div class="book-search">
          <div class="book-search-spinner hidden">
            <i class="fa fa-refresh fa-spin"></i>
          </div>
          <form class="search-bar d-flex" onsubmit="return false;"su>
            <input type="text" id="book-search-input" placeholder="Search" aria-label="Search" maxlength="64" data-hotkeys="s/">
            <i class="fa fa-search search"></i>
            <i class="fa fa-circle-o-notch fa-spin spinner"></i>
          </form>
          <div class="book-search-spinner hidden"></div>
          <ul id="book-search-results"></ul>
        </div>
      </div>
    </div>
  </nav>
  <div class="navbar-clearfix"></div>
</header>
 
  
      <main class="flex">
        <section class="container book-page">
          
<article class="markdown">
    <h1>
        <a href="/2024/10/23/preview-release-of-apache-flink-2.0/">Preview Release of Apache Flink 2.0</a>
    </h1>
    


  October 23, 2024 -



  Xintong Song




    <p><p>The Apache Flink community is actively preparing Flink 2.0, the first major release since Flink 1.0 launched 8 years ago. As a significant milestone, Flink 2.0 is set to introduce numerous innovative features and improvements, along with some compatibility-breaking changes. To facilitate early adaptation to these changes for our users and partner projects (e.g., connectors), and to offer a sneak peek into the exciting new features while gathering feedback, we are now providing a preview release of Flink 2.0.</p>
<p><strong>NOTICE:</strong> Flink 2.0 Preview is not a stable release and should not be used in production environments. While this preview includes most of the breaking changes planned for Flink 2.0, the final release may still subject to additional modifications.</p>
<h1 id="breaking-changes">
  Breaking Changes
  <a class="anchor" href="#breaking-changes">#</a>
</h1>
<h2 id="api">
  API
  <a class="anchor" href="#api">#</a>
</h2>
<p>The following sets of APIs have been completely removed.</p>
<ul>
<li><strong>DataSet API.</strong> Please migrate to <a href="https://nightlies.apache.org/flink/flink-docs-release-2.0-preview1/docs/dev/datastream/overview/">DataStream API</a>, or <a href="https://nightlies.apache.org/flink/flink-docs-release-2.0-preview1/docs/dev/table/overview/">Table API/SQL</a> if applicable. See also <a href="https://nightlies.apache.org/flink/flink-docs-release-1.20/docs/dev/datastream/dataset_migration">How to Migrate from DataSet to DataStream</a>.</li>
<li><strong>Scala DataStream and DataSet API.</strong> Please migrate to the Java <a href="https://nightlies.apache.org/flink/flink-docs-release-2.0-preview1/docs/dev/datastream/overview/">DataStream API</a>.</li>
<li><strong>SourceFuction, SinkFunction and Sink V1.</strong> Please migrate to <a href="https://github.com/apache/flink/blob/master/flink-core/src/main/java/org/apache/flink/api/connector/source/Source.java">Source</a> and <a href="https://github.com/apache/flink/blob/master/flink-core/src/main/java/org/apache/flink/api/connector/sink2/Sink.java">Sink V2</a>.</li>
<li><strong>TableSoure and TableSink.</strong> Please migrate to <a href="https://github.com/apache/flink/blob/master/flink-table/flink-table-common/src/main/java/org/apache/flink/table/connector/source/DynamicTableSource.java">DynamicTableSource</a> and <a href="https://github.com/apache/flink/blob/master/flink-table/flink-table-common/src/main/java/org/apache/flink/table/connector/sink/DynamicTableSink.java">DynamicTableSink</a>. See also <a href="https://nightlies.apache.org/flink/flink-docs-release-2.0-preview1/docs/dev/table/sourcessinks/">User-defined Sources &amp; Sinks</a>.</li>
<li><strong>TableSchema, TableColumn and Types.</strong> Please migrate to <a href="https://github.com/apache/flink/blob/master/flink-table/flink-table-common/src/main/java/org/apache/flink/table/api/Schema.java">Schema</a>, <a href="https://github.com/apache/flink/blob/master/flink-table/flink-table-common/src/main/java/org/apache/flink/table/catalog/Column.java">Column</a> and <a href="https://github.com/apache/flink/blob/master/flink-table/flink-table-common/src/main/java/org/apache/flink/table/api/DataTypes.java">DataTypes</a> respectively.</li>
</ul>
<p>Some deprecated methods have been removed from <strong>DataStream API</strong>. See also the list of <a href="#breaking_programming_apis">breaking programming APIs</a>.</p>
<p>Some deprecated fields have been removed from <strong>REST API</strong>. See also the list of <a href="#breaking_rest_apis">breaking REST APIs</a>.</p>
<p><strong>NOTICE:</strong> You may find some of the removed APIs still exist in the code base, usually in a different package. They are for internal usages only and can be changed / removed anytime without notifications. Please <strong>DO NOT USE</strong> them.</p>
<h3 id="connector-adaption-plan">
  Connector Adaption Plan
  <a class="anchor" href="#connector-adaption-plan">#</a>
</h3>
<p>As SourceFunction, SinkFunction and SinkV1 being removed, existing connectors depending on these APIs will not work on the Flink 2.x series. Here&rsquo;s the plan for adapting the first-party connectors.</p>
<ol>
<li>A new version of Kafka connector, adapted to the API changes, will be released right after the release of Flink 2.0 Preview.</li>
<li>JDBC and ElasticSearch connectors will be adapted by the formal release of Flink 2.0.</li>
<li>We plan to gradually migrate the remaining first-party connectors within 3 subsequent minor releases (i.e., by Flink 2.3).</li>
</ol>
<h2 id="configuration">
  Configuration
  <a class="anchor" href="#configuration">#</a>
</h2>
<p>Configuration options meet the following criteria are removed. See also the list of <a href="#removed_configs">removed configuration options</a>.</p>
<ul>
<li>Annotated as <code>@Public</code> and have been deprecated for at least 2 minor releases.</li>
<li>Annotated as <code>@PublicEvolving</code> and have been deprecated for at least 1 minor releases.</li>
</ul>
<p>The legacy configuration file <code>flink-conf.yaml</code> is no longer supported. Please use <code>config.yaml</code> with standard YAML format instead. A migration tool is provided to convert a legacy <code>flink-conf.yaml</code> into a new <code>config.yaml</code>. See <a href="https://nightlies.apache.org/flink/flink-docs-release-2.0-preview1/docs/deployment/config/#migrate-from-flink-confyaml-to-configyaml">Migrate from flink-conf.yaml to config.yaml</a> for more details.</p>
<p>Configuration APIs that takes java objects as arguments are removed from <code>StreamExecutionEnvironment</code> and <code>ExecutionConfig</code>. They should now be set via <code>Configuration</code> and <code>ConfigOption</code>. See also the list of <a href="#breaking_programming_apis">breaking programming APIs</a>.</p>
<p>To avoid exposing internal interfaces, User-Defined Functions no longer have full access to <code>ExecutionConfig</code>. Instead, necessary functions such as <code>createSerializer()</code>, <code>getGlobalJobParameters()</code> and <code>isObjectReuseEnabled()</code> can now be accessed from <code>RuntimeContext</code> directly.</p>
<h2 id="misc">
  Misc
  <a class="anchor" href="#misc">#</a>
</h2>
<p><strong>State Compatibility</strong> is not guaranteed between 1.x and 2.x.</p>
<p><strong>Java 8</strong> is no longer supported. The minimum Java version supported by Flink now is Java 11.</p>
<p><strong>Legacy Mode of Hybrid Shuffle</strong> is removed.</p>
<h1 id="highlights-of-new-features">
  Highlights of New Features
  <a class="anchor" href="#highlights-of-new-features">#</a>
</h1>
<h2 id="disaggregated-state-storage-and-management">
  Disaggregated State Storage and Management
  <a class="anchor" href="#disaggregated-state-storage-and-management">#</a>
</h2>
<p>The past decade has witnessed a dramatic shift in Flink&rsquo;s deployment mode, workload patterns, and hardware improvements. We&rsquo;ve moved from the map-reduce era where workers are computation-storage tightly coupled nodes to a cloud-native world where containerized deployments on Kubernetes become standard. To enable Flink&rsquo;s Cloud-Native future, we introduce Disaggregated State Storage and Management that uses remote storage as primary storage in Flink 2.0.</p>
<p>This new architecture solves the following challenges brought in the cloud-native era for Flink.</p>
<ol>
<li>Local Disk Constraints in containerization</li>
<li>Spiky Resource Usage caused by compaction in the current state model</li>
<li>Fast Rescaling for jobs with large states (hundreds of Terabytes)</li>
<li>Light and Fast Checkpoint in a native way</li>
</ol>
<p>However, simply extending the state store to read/write from remote DFS is insufficient due to the existing blocking execution model in Flink. In Flink 2.0, we propose asynchronous execution model and introduce ForStDB, a disaggregated statebackend solution for this purpose.</p>
<p>In the preview version, we offer a complete end-to-end trial using <a href="https://github.com/nexmark/nexmark">Nexmark</a> Q20 (SQL Filter Join). This includes:</p>
<ul>
<li>Asynchronous execution: Full support for asynchronous state APIs and checkpointing.</li>
<li>Asynchronous SQL Join operator: Rewrite SQL Join operators to enable asynchronous join execution.</li>
<li>Hybrid Async &amp; Sync Execution: Hybrid SQL Plan + Runtime Execution + State Access</li>
<li>Performance: Demonstrate performance results directly writing to DFS in async execution mode</li>
</ul>
<h2 id="materialized-table">
  Materialized Table
  <a class="anchor" href="#materialized-table">#</a>
</h2>
<p>In Flink 1.20, we introduced Materialized Table as a MVP feature. Materialized Table is an innovative table type in Flink SQL, designed to further streamlining batch and stream data processing while providing a unified development experience. In the upcoming Flink 2.0 release, we are enhancing operational supports for Materialized Tables, including connector integration with cutting-edge lake formats and production-ready schedulers.</p>
<h2 id="adaptive-batch-execution">
  Adaptive Batch Execution
  <a class="anchor" href="#adaptive-batch-execution">#</a>
</h2>
<p>In addition, Flink is continuously enhancing its adaptive batch execution capabilities. The upcoming Flink 2.0 release will introduce dynamic optimization of logical plans, in addition to physical plans, based on insights gained from the execution of previous stages. The initial set of optimization strategies includes the dynamic application of broadcast join and skewed join optimization.</p>
<h2 id="streaming-lakehouse">
  Streaming Lakehouse
  <a class="anchor" href="#streaming-lakehouse">#</a>
</h2>
<p>Represented by the integration of Apache Flink and Apache Paimon, the Streaming Lakehouse architecture has extended the unified data storage, open format and cost-effectiveness of the Lakehouse paradigm to the real-time area. The upcoming Flink 2.0 release marks another significant step in enhancing the integration between Flink and Paimon. The Flink and Paimon communities are collaborating closely to adapt to each other&rsquo;s strengths and fully leverage their cutting-edge features, yielding various improvements including SQL plan optimization utilizing Paimon&rsquo;s rich merge engines, enhanced bucket-aware lookup join performance, and Paimon support for Flink&rsquo;s Materialized Table, Adaptive Batch Execution and Speculative Execution.</p>
<h1 id="appendix">
  Appendix
  <a class="anchor" href="#appendix">#</a>
</h1>
<h2 id="list-of-breaking-change-programming-apis-a-namebreaking_programming_apis-">
  List of breaking change programming APIs <a name="breaking_programming_apis" />
  <a class="anchor" href="#list-of-breaking-change-programming-apis-a-namebreaking_programming_apis-">#</a>
</h2>
<h3 id="removed-classes">
  Removed Classes
  <a class="anchor" href="#removed-classes">#</a>
</h3>
<ul>
<li><code>org.apache.flink.api.common.ExecutionConfig$SerializableSerializer</code></li>
<li><code>org.apache.flink.api.common.ExecutionMode</code></li>
<li><code>org.apache.flink.api.common.InputDependencyConstraint</code></li>
<li><code>org.apache.flink.api.common.restartstrategy.RestartStrategies$ExponentialDelayRestartStrategyConfiguration</code></li>
<li><code>org.apache.flink.api.common.restartstrategy.RestartStrategies$FailureRateRestartStrategyConfiguration</code></li>
<li><code>org.apache.flink.api.common.restartstrategy.RestartStrategies$FallbackRestartStrategyConfiguration</code></li>
<li><code>org.apache.flink.api.common.restartstrategy.RestartStrategies$FixedDelayRestartStrategyConfiguration</code></li>
<li><code>org.apache.flink.api.common.restartstrategy.RestartStrategies$NoRestartStrategyConfiguration</code></li>
<li><code>org.apache.flink.api.common.restartstrategy.RestartStrategies$RestartStrategyConfiguration</code></li>
<li><code>org.apache.flink.api.common.restartstrategy.RestartStrategies</code></li>
<li><code>org.apache.flink.api.common.time.Time</code></li>
<li><code>org.apache.flink.api.connector.sink.Committer</code></li>
<li><code>org.apache.flink.api.connector.sink.GlobalCommitter</code></li>
<li><code>org.apache.flink.api.connector.sink.Sink$InitContext</code></li>
<li><code>org.apache.flink.api.connector.sink.Sink$ProcessingTimeService$ProcessingTimeCallback</code></li>
<li><code>org.apache.flink.api.connector.sink.Sink$ProcessingTimeService</code></li>
<li><code>org.apache.flink.api.connector.sink.SinkWriter$Context</code></li>
<li><code>org.apache.flink.api.connector.sink.SinkWriter</code></li>
<li><code>org.apache.flink.api.connector.sink.Sink</code></li>
<li><code>org.apache.flink.api.connector.sink2.Sink$InitContextWrapper</code></li>
<li><code>org.apache.flink.api.connector.sink2.Sink$InitContext</code></li>
<li><code>org.apache.flink.api.connector.sink2.StatefulSink$StatefulSinkWriter</code></li>
<li><code>org.apache.flink.api.connector.sink2.StatefulSink$WithCompatibleState</code></li>
<li><code>org.apache.flink.api.connector.sink2.StatefulSink</code></li>
<li><code>org.apache.flink.api.connector.sink2.TwoPhaseCommittingSink$PrecommittingSinkWriter</code></li>
<li><code>org.apache.flink.api.connector.sink2.TwoPhaseCommittingSink</code></li>
<li><code>org.apache.flink.api.java.CollectionEnvironment</code></li>
<li><code>org.apache.flink.api.java.DataSet</code></li>
<li><code>org.apache.flink.api.java.ExecutionEnvironmentFactory</code></li>
<li><code>org.apache.flink.api.java.ExecutionEnvironment</code></li>
<li><code>org.apache.flink.api.java.LocalEnvironment</code></li>
<li><code>org.apache.flink.api.java.RemoteEnvironment</code></li>
<li><code>org.apache.flink.api.java.aggregation.Aggregations</code></li>
<li><code>org.apache.flink.api.java.aggregation.UnsupportedAggregationTypeException</code></li>
<li><code>org.apache.flink.api.java.functions.FlatMapIterator</code></li>
<li><code>org.apache.flink.api.java.functions.FunctionAnnotation$ForwardedFieldsFirst</code></li>
<li><code>org.apache.flink.api.java.functions.FunctionAnnotation$ForwardedFieldsSecond</code></li>
<li><code>org.apache.flink.api.java.functions.FunctionAnnotation$ForwardedFields</code></li>
<li><code>org.apache.flink.api.java.functions.FunctionAnnotation$NonForwardedFieldsFirst</code></li>
<li><code>org.apache.flink.api.java.functions.FunctionAnnotation$NonForwardedFieldsSecond</code></li>
<li><code>org.apache.flink.api.java.functions.FunctionAnnotation$NonForwardedFields</code></li>
<li><code>org.apache.flink.api.java.functions.FunctionAnnotation$ReadFieldsFirst</code></li>
<li><code>org.apache.flink.api.java.functions.FunctionAnnotation$ReadFieldsSecond</code></li>
<li><code>org.apache.flink.api.java.functions.FunctionAnnotation$ReadFields</code></li>
<li><code>org.apache.flink.api.java.functions.FunctionAnnotation</code></li>
<li><code>org.apache.flink.api.java.functions.GroupReduceIterator</code></li>
<li><code>org.apache.flink.api.java.io.CollectionInputFormat</code></li>
<li><code>org.apache.flink.api.java.io.CsvOutputFormat</code></li>
<li><code>org.apache.flink.api.java.io.CsvReader</code></li>
<li><code>org.apache.flink.api.java.io.DiscardingOutputFormat</code></li>
<li><code>org.apache.flink.api.java.io.IteratorInputFormat</code></li>
<li><code>org.apache.flink.api.java.io.LocalCollectionOutputFormat</code></li>
<li><code>org.apache.flink.api.java.io.ParallelIteratorInputFormat</code></li>
<li><code>org.apache.flink.api.java.io.PrimitiveInputFormat</code></li>
<li><code>org.apache.flink.api.java.io.PrintingOutputFormat</code></li>
<li><code>org.apache.flink.api.java.io.RowCsvInputFormat</code></li>
<li><code>org.apache.flink.api.java.io.SplitDataProperties$SourcePartitionerMarker</code></li>
<li><code>org.apache.flink.api.java.io.SplitDataProperties</code></li>
<li><code>org.apache.flink.api.java.io.TextInputFormat</code></li>
<li><code>org.apache.flink.api.java.io.TextOutputFormat$TextFormatter</code></li>
<li><code>org.apache.flink.api.java.io.TextOutputFormat</code></li>
<li><code>org.apache.flink.api.java.io.TextValueInputFormat</code></li>
<li><code>org.apache.flink.api.java.io.TypeSerializerInputFormat</code></li>
<li><code>org.apache.flink.api.java.io.TypeSerializerOutputFormat</code></li>
<li><code>org.apache.flink.api.java.operators.AggregateOperator</code></li>
<li><code>org.apache.flink.api.java.operators.CoGroupOperator$CoGroupOperatorSets</code></li>
<li><code>org.apache.flink.api.java.operators.CoGroupOperator</code></li>
<li><code>org.apache.flink.api.java.operators.CrossOperator$DefaultCross</code></li>
<li><code>org.apache.flink.api.java.operators.CrossOperator$ProjectCross</code></li>
<li><code>org.apache.flink.api.java.operators.CrossOperator</code></li>
<li><code>org.apache.flink.api.java.operators.CustomUnaryOperation</code></li>
<li><code>org.apache.flink.api.java.operators.DataSink</code></li>
<li><code>org.apache.flink.api.java.operators.DataSource</code></li>
<li><code>org.apache.flink.api.java.operators.DeltaIteration$SolutionSetPlaceHolder</code></li>
<li><code>org.apache.flink.api.java.operators.DeltaIteration$WorksetPlaceHolder</code></li>
<li><code>org.apache.flink.api.java.operators.DeltaIterationResultSet</code></li>
<li><code>org.apache.flink.api.java.operators.DeltaIteration</code></li>
<li><code>org.apache.flink.api.java.operators.DistinctOperator</code></li>
<li><code>org.apache.flink.api.java.operators.FilterOperator</code></li>
<li><code>org.apache.flink.api.java.operators.FlatMapOperator</code></li>
<li><code>org.apache.flink.api.java.operators.GroupCombineOperator</code></li>
<li><code>org.apache.flink.api.java.operators.GroupReduceOperator</code></li>
<li><code>org.apache.flink.api.java.operators.Grouping</code></li>
<li><code>org.apache.flink.api.java.operators.IterativeDataSet</code></li>
<li><code>org.apache.flink.api.java.operators.JoinOperator$DefaultJoin</code></li>
<li><code>org.apache.flink.api.java.operators.JoinOperator$EquiJoin</code></li>
<li><code>org.apache.flink.api.java.operators.JoinOperator$JoinOperatorSets$JoinOperatorSetsPredicate</code></li>
<li><code>org.apache.flink.api.java.operators.JoinOperator$JoinOperatorSets</code></li>
<li><code>org.apache.flink.api.java.operators.JoinOperator$ProjectJoin</code></li>
<li><code>org.apache.flink.api.java.operators.JoinOperator</code></li>
<li><code>org.apache.flink.api.java.operators.MapOperator</code></li>
<li><code>org.apache.flink.api.java.operators.MapPartitionOperator</code></li>
<li><code>org.apache.flink.api.java.operators.Operator</code></li>
<li><code>org.apache.flink.api.java.operators.PartitionOperator</code></li>
<li><code>org.apache.flink.api.java.operators.ProjectOperator</code></li>
<li><code>org.apache.flink.api.java.operators.ReduceOperator</code></li>
<li><code>org.apache.flink.api.java.operators.SingleInputOperator</code></li>
<li><code>org.apache.flink.api.java.operators.SingleInputUdfOperator</code></li>
<li><code>org.apache.flink.api.java.operators.SortPartitionOperator</code></li>
<li><code>org.apache.flink.api.java.operators.SortedGrouping</code></li>
<li><code>org.apache.flink.api.java.operators.TwoInputOperator</code></li>
<li><code>org.apache.flink.api.java.operators.TwoInputUdfOperator</code></li>
<li><code>org.apache.flink.api.java.operators.UdfOperator</code></li>
<li><code>org.apache.flink.api.java.operators.UnionOperator</code></li>
<li><code>org.apache.flink.api.java.operators.UnsortedGrouping</code></li>
<li><code>org.apache.flink.api.java.operators.join.JoinFunctionAssigner</code></li>
<li><code>org.apache.flink.api.java.operators.join.JoinOperatorSetsBase$JoinOperatorSetsPredicateBase</code></li>
<li><code>org.apache.flink.api.java.operators.join.JoinOperatorSetsBase</code></li>
<li><code>org.apache.flink.api.java.operators.join.JoinType</code></li>
<li><code>org.apache.flink.api.java.summarize.BooleanColumnSummary</code></li>
<li><code>org.apache.flink.api.java.summarize.ColumnSummary</code></li>
<li><code>org.apache.flink.api.java.summarize.NumericColumnSummary</code></li>
<li><code>org.apache.flink.api.java.summarize.ObjectColumnSummary</code></li>
<li><code>org.apache.flink.api.java.summarize.StringColumnSummary</code></li>
<li><code>org.apache.flink.api.java.utils.AbstractParameterTool</code></li>
<li><code>org.apache.flink.api.java.utils.DataSetUtils</code></li>
<li><code>org.apache.flink.api.java.utils.MultipleParameterTool</code></li>
<li><code>org.apache.flink.api.java.utils.ParameterTool</code></li>
<li><code>org.apache.flink.configuration.AkkaOptions</code></li>
<li><code>org.apache.flink.connector.file.src.reader.FileRecordFormat$Reader</code></li>
<li><code>org.apache.flink.connector.file.src.reader.FileRecordFormat</code></li>
<li><code>org.apache.flink.connector.testframe.external.sink.DataStreamSinkV1ExternalContext</code></li>
<li><code>org.apache.flink.core.execution.RestoreMode</code></li>
<li><code>org.apache.flink.datastream.api.stream.KeyedPartitionStream$TwoKeyedPartitionStreams</code></li>
<li><code>org.apache.flink.datastream.api.stream.NonKeyedPartitionStream$TwoNonKeyedPartitionStreams</code></li>
<li><code>org.apache.flink.formats.avro.AvroRowDeserializationSchema</code></li>
<li><code>org.apache.flink.formats.csv.CsvRowDeserializationSchema$Builder</code></li>
<li><code>org.apache.flink.formats.csv.CsvRowDeserializationSchema</code></li>
<li><code>org.apache.flink.formats.csv.CsvRowSerializationSchema$Builder</code></li>
<li><code>org.apache.flink.formats.csv.CsvRowSerializationSchema</code></li>
<li><code>org.apache.flink.formats.json.JsonRowDeserializationSchema$Builder</code></li>
<li><code>org.apache.flink.formats.json.JsonRowDeserializationSchema</code></li>
<li><code>org.apache.flink.formats.json.JsonRowSerializationSchema$Builder</code></li>
<li><code>org.apache.flink.formats.json.JsonRowSerializationSchema</code></li>
<li><code>org.apache.flink.metrics.reporter.InstantiateViaFactory</code></li>
<li><code>org.apache.flink.metrics.reporter.InterceptInstantiationViaReflection</code></li>
<li><code>org.apache.flink.runtime.jobgraph.SavepointConfigOptions</code></li>
<li><code>org.apache.flink.runtime.state.CheckpointListener</code></li>
<li><code>org.apache.flink.runtime.state.filesystem.FsStateBackendFactory</code></li>
<li><code>org.apache.flink.runtime.state.filesystem.FsStateBackend</code></li>
<li><code>org.apache.flink.runtime.state.memory.MemoryStateBackendFactory</code></li>
<li><code>org.apache.flink.runtime.state.memory.MemoryStateBackend</code></li>
<li><code>org.apache.flink.state.api.BootstrapTransformation</code></li>
<li><code>org.apache.flink.state.api.EvictingWindowReader</code></li>
<li><code>org.apache.flink.state.api.ExistingSavepoint</code></li>
<li><code>org.apache.flink.state.api.KeyedOperatorTransformation</code></li>
<li><code>org.apache.flink.state.api.NewSavepoint</code></li>
<li><code>org.apache.flink.state.api.OneInputOperatorTransformation</code></li>
<li><code>org.apache.flink.state.api.Savepoint</code></li>
<li><code>org.apache.flink.state.api.WindowReader</code></li>
<li><code>org.apache.flink.state.api.WindowedOperatorTransformation</code></li>
<li><code>org.apache.flink.state.api.WritableSavepoint</code></li>
<li><code>org.apache.flink.streaming.api.TimeCharacteristic</code></li>
<li><code>org.apache.flink.streaming.api.checkpoint.ExternallyInducedSource$CheckpointTrigger</code></li>
<li><code>org.apache.flink.streaming.api.checkpoint.ExternallyInducedSource</code></li>
<li><code>org.apache.flink.streaming.api.connector.sink2.WithPostCommitTopology</code></li>
<li><code>org.apache.flink.streaming.api.connector.sink2.WithPreCommitTopology</code></li>
<li><code>org.apache.flink.streaming.api.connector.sink2.WithPreWriteTopology</code></li>
<li><code>org.apache.flink.streaming.api.datastream.IterativeStream$ConnectedIterativeStreams</code></li>
<li><code>org.apache.flink.streaming.api.environment.CheckpointConfig$ExternalizedCheckpointCleanup</code></li>
<li><code>org.apache.flink.streaming.api.environment.ExecutionCheckpointingOptions</code></li>
<li><code>org.apache.flink.streaming.api.environment.StreamPipelineOptions</code></li>
<li><code>org.apache.flink.streaming.api.functions.AscendingTimestampExtractor</code></li>
<li><code>org.apache.flink.streaming.api.functions.sink.DiscardingSink</code></li>
<li><code>org.apache.flink.streaming.api.functions.sink.OutputFormatSinkFunction</code></li>
<li><code>org.apache.flink.streaming.api.functions.sink.PrintSinkFunction</code></li>
<li><code>org.apache.flink.streaming.api.functions.sink.RichSinkFunction</code></li>
<li><code>org.apache.flink.streaming.api.functions.sink.SinkFunction$Context</code></li>
<li><code>org.apache.flink.streaming.api.functions.sink.SinkFunction</code></li>
<li><code>org.apache.flink.streaming.api.functions.sink.SocketClientSink</code></li>
<li><code>org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction</code></li>
<li><code>org.apache.flink.streaming.api.functions.sink.WriteFormatAsCsv</code></li>
<li><code>org.apache.flink.streaming.api.functions.sink.WriteFormatAsText</code></li>
<li><code>org.apache.flink.streaming.api.functions.sink.WriteFormat</code></li>
<li><code>org.apache.flink.streaming.api.functions.sink.WriteSinkFunctionByMillis</code></li>
<li><code>org.apache.flink.streaming.api.functions.sink.WriteSinkFunction</code></li>
<li><code>org.apache.flink.streaming.api.functions.sink.filesystem.StreamingFileSink$BulkFormatBuilder</code></li>
<li><code>org.apache.flink.streaming.api.functions.sink.filesystem.StreamingFileSink$DefaultBulkFormatBuilder</code></li>
<li><code>org.apache.flink.streaming.api.functions.sink.filesystem.StreamingFileSink$DefaultRowFormatBuilder</code></li>
<li><code>org.apache.flink.streaming.api.functions.sink.filesystem.StreamingFileSink$RowFormatBuilder</code></li>
<li><code>org.apache.flink.streaming.api.functions.sink.filesystem.StreamingFileSink</code></li>
<li><code>org.apache.flink.streaming.api.functions.source.FromElementsFunction</code></li>
<li><code>org.apache.flink.streaming.api.functions.source.FromIteratorFunction</code></li>
<li><code>org.apache.flink.streaming.api.functions.source.FromSplittableIteratorFunction</code></li>
<li><code>org.apache.flink.streaming.api.functions.source.MessageAcknowledgingSourceBase</code></li>
<li><code>org.apache.flink.streaming.api.functions.source.MultipleIdsMessageAcknowledgingSourceBase</code></li>
<li><code>org.apache.flink.streaming.api.functions.source.ParallelSourceFunction</code></li>
<li><code>org.apache.flink.streaming.api.functions.source.RichParallelSourceFunction</code></li>
<li><code>org.apache.flink.streaming.api.functions.source.RichSourceFunction</code></li>
<li><code>org.apache.flink.streaming.api.functions.source.SocketTextStreamFunction</code></li>
<li><code>org.apache.flink.streaming.api.functions.source.SourceFunction$SourceContext</code></li>
<li><code>org.apache.flink.streaming.api.functions.source.SourceFunction</code></li>
<li><code>org.apache.flink.streaming.api.functions.source.StatefulSequenceSource</code></li>
<li><code>org.apache.flink.streaming.api.functions.source.datagen.DataGeneratorSource</code></li>
<li><code>org.apache.flink.streaming.api.functions.windowing.RichProcessAllWindowFunction</code></li>
<li><code>org.apache.flink.streaming.api.functions.windowing.RichProcessWindowFunction</code></li>
<li><code>org.apache.flink.streaming.api.operators.SetupableStreamOperator</code></li>
<li><code>org.apache.flink.streaming.api.operators.YieldingOperatorFactory</code></li>
<li><code>org.apache.flink.streaming.api.windowing.time.Time</code></li>
<li><code>org.apache.flink.streaming.util.serialization.AbstractDeserializationSchema</code></li>
<li><code>org.apache.flink.streaming.util.serialization.DeserializationSchema</code></li>
<li><code>org.apache.flink.streaming.util.serialization.SerializationSchema</code></li>
<li><code>org.apache.flink.streaming.util.serialization.SimpleStringSchema</code></li>
<li><code>org.apache.flink.streaming.util.serialization.TypeInformationSerializationSchema</code></li>
<li><code>org.apache.flink.table.api.TableColumn$ComputedColumn</code></li>
<li><code>org.apache.flink.table.api.TableColumn$MetadataColumn</code></li>
<li><code>org.apache.flink.table.api.TableColumn$PhysicalColumn</code></li>
<li><code>org.apache.flink.table.api.TableColumn</code></li>
<li><code>org.apache.flink.table.api.TableSchema$Builder</code></li>
<li><code>org.apache.flink.table.api.TableSchema</code></li>
<li><code>org.apache.flink.table.api.constraints.Constraint$ConstraintType</code></li>
<li><code>org.apache.flink.table.api.constraints.Constraint</code></li>
<li><code>org.apache.flink.table.api.constraints.UniqueConstraint</code></li>
<li><code>org.apache.flink.table.connector.sink.SinkFunctionProvider</code></li>
<li><code>org.apache.flink.table.connector.sink.SinkProvider</code></li>
<li><code>org.apache.flink.table.connector.source.AsyncTableFunctionProvider</code></li>
<li><code>org.apache.flink.table.connector.source.SourceFunctionProvider</code></li>
<li><code>org.apache.flink.table.connector.source.TableFunctionProvider</code></li>
<li><code>org.apache.flink.table.descriptors.Descriptor</code></li>
<li><code>org.apache.flink.table.descriptors.RowtimeValidator</code></li>
<li><code>org.apache.flink.table.descriptors.Rowtime</code></li>
<li><code>org.apache.flink.table.descriptors.SchemaValidator</code></li>
<li><code>org.apache.flink.table.descriptors.Schema</code></li>
<li><code>org.apache.flink.table.factories.StreamTableSinkFactory</code></li>
<li><code>org.apache.flink.table.factories.StreamTableSourceFactory</code></li>
<li><code>org.apache.flink.table.factories.TableFactory</code></li>
<li><code>org.apache.flink.table.factories.TableSinkFactory$Context</code></li>
<li><code>org.apache.flink.table.factories.TableSinkFactory</code></li>
<li><code>org.apache.flink.table.factories.TableSourceFactory$Context</code></li>
<li><code>org.apache.flink.table.factories.TableSourceFactory</code></li>
<li><code>org.apache.flink.table.planner.codegen.agg.batch.HashAggCodeGenerator$</code></li>
<li><code>org.apache.flink.table.planner.plan.metadata.FlinkRelMdRowCount$</code></li>
<li><code>org.apache.flink.table.planner.plan.optimize.RelNodeBlockPlanBuilder$</code></li>
<li><code>org.apache.flink.table.planner.plan.rules.logical.JoinDeriveNullFilterRule$</code></li>
<li><code>org.apache.flink.table.planner.plan.rules.physical.batch.BatchPhysicalJoinRuleBase$</code></li>
<li><code>org.apache.flink.table.planner.plan.rules.physical.batch.BatchPhysicalSortMergeJoinRule$</code></li>
<li><code>org.apache.flink.table.planner.plan.rules.physical.batch.BatchPhysicalSortRule$</code></li>
<li><code>org.apache.flink.table.planner.plan.rules.physical.stream.IncrementalAggregateRule$</code></li>
<li><code>org.apache.flink.table.planner.plan.utils.FlinkRexUtil$</code></li>
<li><code>org.apache.flink.table.sinks.AppendStreamTableSink</code></li>
<li><code>org.apache.flink.table.sinks.OutputFormatTableSink</code></li>
<li><code>org.apache.flink.table.sinks.OverwritableTableSink</code></li>
<li><code>org.apache.flink.table.sinks.PartitionableTableSink</code></li>
<li><code>org.apache.flink.table.sinks.RetractStreamTableSink</code></li>
<li><code>org.apache.flink.table.sinks.TableSink</code></li>
<li><code>org.apache.flink.table.sinks.UpsertStreamTableSink</code></li>
<li><code>org.apache.flink.table.sources.DefinedFieldMapping</code></li>
<li><code>org.apache.flink.table.sources.DefinedProctimeAttribute</code></li>
<li><code>org.apache.flink.table.sources.DefinedRowtimeAttributes</code></li>
<li><code>org.apache.flink.table.sources.FieldComputer</code></li>
<li><code>org.apache.flink.table.sources.InputFormatTableSource</code></li>
<li><code>org.apache.flink.table.sources.LimitableTableSource</code></li>
<li><code>org.apache.flink.table.sources.LookupableTableSource</code></li>
<li><code>org.apache.flink.table.sources.NestedFieldsProjectableTableSource</code></li>
<li><code>org.apache.flink.table.sources.PartitionableTableSource</code></li>
<li><code>org.apache.flink.table.sources.ProjectableTableSource</code></li>
<li><code>org.apache.flink.table.sources.TableSource</code></li>
<li><code>org.apache.flink.table.sources.tsextractors.ExistingField</code></li>
<li><code>org.apache.flink.table.sources.tsextractors.StreamRecordTimestamp</code></li>
<li><code>org.apache.flink.table.sources.tsextractors.TimestampExtractor</code></li>
<li><code>org.apache.flink.table.types.logical.TypeInformationRawType</code></li>
<li><code>org.apache.flink.table.utils.TypeStringUtils</code></li>
<li><code>org.apache.flink.walkthrough.common.sink.AlertSink</code></li>
<li><code>org.apache.flink.walkthrough.common.source.TransactionSource</code></li>
</ul>
<h3 id="modified-classes">
  Modified Classes
  <a class="anchor" href="#modified-classes">#</a>
</h3>
<ul>
<li><code>org.apache.flink.table.api.config.ExecutionConfigOptions</code>
<ul>
<li>field removed:
<ul>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.Boolean&gt; TABLE_EXEC_LEGACY_TRANSFORMATION_UIDS</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.String&gt; TABLE_EXEC_SHUFFLE_MODE</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.table.api.config.LookupJoinHintOptions</code>
<ul>
<li>method modified:
<ul>
<li><code>org.apache.flink.shaded.guava32.com.google.common.collect.ImmutableSet&lt;org.apache.flink.configuration.ConfigOption&gt;&lt;org.apache.flink.configuration.ConfigOption&gt; (&lt;-org.apache.flink.shaded.guava31.com.google.common.collect.ImmutableSet&lt;org.apache.flink.configuration.ConfigOption&gt;&lt;org.apache.flink.configuration.ConfigOption&gt;) getRequiredOptions()</code></li>
<li><code>org.apache.flink.shaded.guava32.com.google.common.collect.ImmutableSet&lt;org.apache.flink.configuration.ConfigOption&gt;&lt;org.apache.flink.configuration.ConfigOption&gt; (&lt;-org.apache.flink.shaded.guava31.com.google.common.collect.ImmutableSet&lt;org.apache.flink.configuration.ConfigOption&gt;&lt;org.apache.flink.configuration.ConfigOption&gt;) getSupportedOptions()</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.table.api.config.OptimizerConfigOptions</code>
<ul>
<li>field removed:
<ul>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.Boolean&gt; TABLE_OPTIMIZER_SOURCE_PREDICATE_PUSHDOWN_ENABLED</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.Boolean&gt; TABLE_OPTIMIZER_SOURCE_AGGREGATE_PUSHDOWN_ENABLED</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.table.api.Table</code>
<ul>
<li>method modified:
<ul>
<li><code>org.apache.flink.table.legacy.api.TableSchema (&lt;-org.apache.flink.table.api.TableSchema) getSchema()</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.table.api.TableConfig</code>
<ul>
<li>method removed:
<ul>
<li><code>void setIdleStateRetentionTime(org.apache.flink.api.common.time.Time, org.apache.flink.api.common.time.Time)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.table.api.TableResult</code>
<ul>
<li>method modified:
<ul>
<li><code>org.apache.flink.table.legacy.api.TableSchema (&lt;-org.apache.flink.table.api.TableSchema) getTableSchema()</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.table.catalog.CatalogBaseTable</code>
<ul>
<li>method modified:
<ul>
<li><code>org.apache.flink.table.legacy.api.TableSchema (&lt;-org.apache.flink.table.api.TableSchema) getSchema()</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.table.catalog.ResolvedCatalogBaseTable</code>
<ul>
<li>method modified:
<ul>
<li><code>org.apache.flink.table.legacy.api.TableSchema (&lt;-org.apache.flink.table.api.TableSchema) getSchema()</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.table.functions.FunctionContext</code>
<ul>
<li>constructor removed:
<ul>
<li><code>FunctionContext(org.apache.flink.api.common.functions.RuntimeContext, java.lang.ClassLoader, org.apache.flink.configuration.Configuration)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.api.common.eventtime.WatermarksWithIdleness</code>
<ul>
<li>constructor removed:
<ul>
<li><code>WatermarksWithIdleness(org.apache.flink.api.common.eventtime.WatermarkGenerator&lt;T&gt;, java.time.Duration)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.api.common.ExecutionConfig</code>
<ul>
<li>field removed:
<ul>
<li><code>int PARALLELISM_AUTO_MAX</code></li>
</ul>
</li>
<li>method removed:
<ul>
<li><code>void addDefaultKryoSerializer(java.lang.Class&lt;?&gt;, com.esotericsoftware.kryo.Serializer&lt;?&gt;)</code></li>
<li><code>void addDefaultKryoSerializer(java.lang.Class&lt;?&gt;, java.lang.Class&lt;? extends com.esotericsoftware.kryo.Serializer&lt;? extends ?&gt;&gt;)</code></li>
<li><code>boolean canEqual(java.lang.Object)</code></li>
<li><code>void disableAutoTypeRegistration()</code></li>
<li><code>void disableForceAvro()</code></li>
<li><code>void disableForceKryo()</code></li>
<li><code>void disableGenericTypes()</code></li>
<li><code>void enableForceAvro()</code></li>
<li><code>void enableForceKryo()</code></li>
<li><code>void enableGenericTypes()</code></li>
<li><code>org.apache.flink.api.common.InputDependencyConstraint getDefaultInputDependencyConstraint()</code></li>
<li><code>java.util.LinkedHashMap&lt;java.lang.Class&lt;?&gt;,java.lang.Class&lt;com.esotericsoftware.kryo.Serializer&lt;? extends ?&gt;&gt;&gt; getDefaultKryoSerializerClasses()</code></li>
<li><code>java.util.LinkedHashMap&lt;java.lang.Class&lt;?&gt;,org.apache.flink.api.common.ExecutionConfig$SerializableSerializer&lt;?&gt;&gt; getDefaultKryoSerializers()</code></li>
<li><code>org.apache.flink.api.common.ExecutionMode getExecutionMode()</code></li>
<li><code>long getExecutionRetryDelay()</code></li>
<li><code>int getNumberOfExecutionRetries()</code></li>
<li><code>java.util.LinkedHashSet&lt;java.lang.Class&lt;?&gt;&gt; getRegisteredKryoTypes()</code></li>
<li><code>java.util.LinkedHashSet&lt;java.lang.Class&lt;?&gt;&gt; getRegisteredPojoTypes()</code></li>
<li><code>java.util.LinkedHashMap&lt;java.lang.Class&lt;?&gt;,java.lang.Class&lt;com.esotericsoftware.kryo.Serializer&lt;? extends ?&gt;&gt;&gt; getRegisteredTypesWithKryoSerializerClasses()</code></li>
<li><code>java.util.LinkedHashMap&lt;java.lang.Class&lt;?&gt;,org.apache.flink.api.common.ExecutionConfig$SerializableSerializer&lt;?&gt;&gt; getRegisteredTypesWithKryoSerializers()</code></li>
<li><code>org.apache.flink.api.common.restartstrategy.RestartStrategies$RestartStrategyConfiguration getRestartStrategy()</code></li>
<li><code>boolean hasGenericTypesDisabled()</code></li>
<li><code>boolean isAutoTypeRegistrationDisabled()</code></li>
<li><code>boolean isForceAvroEnabled()</code></li>
<li><code>boolean isForceKryoEnabled()</code></li>
<li><code>void registerKryoType(java.lang.Class&lt;?&gt;)</code></li>
<li><code>void registerPojoType(java.lang.Class&lt;?&gt;)</code></li>
<li><code>void registerTypeWithKryoSerializer(java.lang.Class&lt;?&gt;, com.esotericsoftware.kryo.Serializer&lt;?&gt;)</code></li>
<li><code>void registerTypeWithKryoSerializer(java.lang.Class&lt;?&gt;, java.lang.Class&lt;? extends com.esotericsoftware.kryo.Serializer&gt;)</code></li>
<li><code>void setDefaultInputDependencyConstraint(org.apache.flink.api.common.InputDependencyConstraint)</code></li>
<li><code>void setExecutionMode(org.apache.flink.api.common.ExecutionMode)</code></li>
<li><code>org.apache.flink.api.common.ExecutionConfig setExecutionRetryDelay(long)</code></li>
<li><code>org.apache.flink.api.common.ExecutionConfig setNumberOfExecutionRetries(int)</code></li>
<li><code>void setRestartStrategy(org.apache.flink.api.common.restartstrategy.RestartStrategies$RestartStrategyConfiguration)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.api.common.functions.RichFunction</code>
<ul>
<li>method removed:
<ul>
<li><code>void open(org.apache.flink.configuration.Configuration)</code></li>
</ul>
</li>
<li>method modified:
<ul>
<li><code>(&lt;- NON_ABSTRACT) void open(org.apache.flink.api.common.functions.OpenContext)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.api.common.functions.RuntimeContext</code>
<ul>
<li>method removed:
<ul>
<li><code>int getAttemptNumber()</code></li>
<li><code>org.apache.flink.api.common.ExecutionConfig getExecutionConfig()</code></li>
<li><code>int getIndexOfThisSubtask()</code></li>
<li><code>org.apache.flink.api.common.JobID getJobId()</code></li>
<li><code>int getMaxNumberOfParallelSubtasks()</code></li>
<li><code>int getNumberOfParallelSubtasks()</code></li>
<li><code>java.lang.String getTaskName()</code></li>
<li><code>java.lang.String getTaskNameWithSubtasks()</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.api.common.io.BinaryInputFormat</code>
<ul>
<li>field removed:
<ul>
<li><code>java.lang.String BLOCK_SIZE_PARAMETER_KEY</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.api.common.io.BinaryOutputFormat</code>
<ul>
<li>field removed:
<ul>
<li><code>java.lang.String BLOCK_SIZE_PARAMETER_KEY</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.api.common.io.FileInputFormat</code>
<ul>
<li>field removed:
<ul>
<li><code>java.lang.String ENUMERATE_NESTED_FILES_FLAG</code></li>
</ul>
</li>
<li>method removed:
<ul>
<li><code>org.apache.flink.core.fs.Path getFilePath()</code></li>
<li><code>boolean supportsMultiPaths()</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.api.common.io.FileOutputFormat</code>
<ul>
<li>field removed:
<ul>
<li><code>java.lang.String FILE_PARAMETER_KEY</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.api.common.io.FinalizeOnMaster</code>
<ul>
<li>method removed:
<ul>
<li><code>void finalizeGlobal(int)</code></li>
</ul>
</li>
<li>method modified:
<ul>
<li><code>(&lt;- NON_ABSTRACT) void finalizeGlobal(org.apache.flink.api.common.io.FinalizeOnMaster$FinalizationContext)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.api.common.io.OutputFormat</code>
<ul>
<li>method removed:
<ul>
<li><code>void open(int, int)</code></li>
</ul>
</li>
<li>method modified:
<ul>
<li><code>(&lt;- NON_ABSTRACT) void open(org.apache.flink.api.common.io.OutputFormat$InitializationContext)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.api.common.JobExecutionResult</code>
<ul>
<li>method removed:
<ul>
<li><code>org.apache.flink.api.common.JobExecutionResult fromJobSubmissionResult(org.apache.flink.api.common.JobSubmissionResult)</code></li>
<li><code>java.lang.Integer getIntCounterResult(java.lang.String)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.api.common.serialization.SerializerConfig</code>
<ul>
<li>method removed:
<ul>
<li><code>java.util.LinkedHashMap&lt;java.lang.Class&lt;?&gt;,org.apache.flink.api.common.ExecutionConfig$SerializableSerializer&lt;?&gt;&gt; getDefaultKryoSerializers()</code></li>
<li><code>java.util.LinkedHashMap&lt;java.lang.Class&lt;?&gt;,org.apache.flink.api.common.ExecutionConfig$SerializableSerializer&lt;?&gt;&gt; getRegisteredTypesWithKryoSerializers()</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.api.common.state.StateTtlConfig</code>
<ul>
<li>method removed:
<ul>
<li><code>org.apache.flink.api.common.time.Time getTtl()</code></li>
<li><code>org.apache.flink.api.common.state.StateTtlConfig$Builder newBuilder(org.apache.flink.api.common.time.Time)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.api.common.state.StateTtlConfig$Builder</code>
<ul>
<li>constructor removed:
<ul>
<li><code>StateTtlConfig$Builder(org.apache.flink.api.common.time.Time)</code></li>
</ul>
</li>
<li>method removed:
<ul>
<li><code>org.apache.flink.api.common.state.StateTtlConfig$Builder setTtl(org.apache.flink.api.common.time.Time)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.api.common.typeinfo.TypeInformation</code>
<ul>
<li>method modified:
<ul>
<li><code>(&lt;- NON_ABSTRACT) org.apache.flink.api.common.typeutils.TypeSerializer&lt;T&gt;&lt;T&gt; createSerializer(org.apache.flink.api.common.serialization.SerializerConfig)</code></li>
</ul>
</li>
<li>method removed:
<ul>
<li><code>org.apache.flink.api.common.typeutils.TypeSerializer&lt;T&gt; createSerializer(org.apache.flink.api.common.ExecutionConfig)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.api.common.typeutils.TypeSerializerSnapshot</code>
<ul>
<li>method removed:
<ul>
<li><code>org.apache.flink.api.common.typeutils.TypeSerializerSchemaCompatibility&lt;T&gt; resolveSchemaCompatibility(org.apache.flink.api.common.typeutils.TypeSerializer&lt;T&gt;)</code></li>
</ul>
</li>
<li>method modified:
<ul>
<li><code>(&lt;- NON_ABSTRACT) org.apache.flink.api.common.typeutils.TypeSerializerSchemaCompatibility&lt;T&gt;&lt;T&gt; resolveSchemaCompatibility(org.apache.flink.api.common.typeutils.TypeSerializerSnapshot&lt;T&gt;&lt;T&gt;)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.api.connector.sink2.Sink</code>
<ul>
<li>method removed:
<ul>
<li><code>org.apache.flink.api.connector.sink2.SinkWriter&lt;InputT&gt; createWriter(org.apache.flink.api.connector.sink2.Sink$InitContext)</code></li>
</ul>
</li>
<li>method modified:
<ul>
<li><code>(&lt;- NON_ABSTRACT) org.apache.flink.api.connector.sink2.SinkWriter&lt;InputT&gt;&lt;InputT&gt; createWriter(org.apache.flink.api.connector.sink2.WriterInitContext)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.api.java.typeutils.PojoTypeInfo</code>
<ul>
<li>method removed:
<ul>
<li><code>org.apache.flink.api.java.typeutils.runtime.PojoSerializer&lt;T&gt; createPojoSerializer(org.apache.flink.api.common.ExecutionConfig)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.api.java.typeutils.RowTypeInfo</code>
<ul>
<li>method removed:
<ul>
<li><code>org.apache.flink.api.common.typeutils.TypeSerializer&lt;org.apache.flink.types.Row&gt; createLegacySerializer(org.apache.flink.api.common.serialization.SerializerConfig)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.configuration.CheckpointingOptions</code>
<ul>
<li>field removed:
<ul>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.Boolean&gt; LOCAL_RECOVERY</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.String&gt; STATE_BACKEND</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.Boolean&gt; ASYNC_SNAPSHOTS</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.configuration.ClusterOptions</code>
<ul>
<li>field removed:
<ul>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.Boolean&gt; FINE_GRAINED_SHUFFLE_MODE_ALL_BLOCKING</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.Boolean&gt; EVENLY_SPREAD_OUT_SLOTS_STRATEGY</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.configuration.ConfigConstants</code>
<ul>
<li>field removed:
<ul>
<li><code>java.lang.String HA_ZOOKEEPER_LEADER_PATH</code></li>
<li><code>double DEFAULT_AKKA_WATCH_THRESHOLD</code></li>
<li><code>int DEFAULT_JOB_MANAGER_IPC_PORT</code></li>
<li><code>java.lang.String JOB_MANAGER_WEB_TMPDIR_KEY</code></li>
<li><code>int DEFAULT_TASK_MANAGER_MEMORY_SEGMENT_SIZE</code></li>
<li><code>java.lang.String METRICS_SCOPE_NAMING_TASK</code></li>
<li><code>java.lang.String ZOOKEEPER_NAMESPACE_KEY</code></li>
<li><code>int DEFAULT_AKKA_DISPATCHER_THROUGHPUT</code></li>
<li><code>java.lang.String RESTART_STRATEGY_FIXED_DELAY_ATTEMPTS</code></li>
<li><code>java.lang.String MESOS_MASTER_URL</code></li>
<li><code>java.lang.String FLINK_BASE_DIR_PATH_KEY</code></li>
<li><code>java.lang.String JOB_MANAGER_WEB_SSL_ENABLED</code></li>
<li><code>java.lang.String YARN_APPLICATION_TAGS</code></li>
<li><code>java.lang.String HDFS_SITE_CONFIG</code></li>
<li><code>java.lang.String EXECUTION_RETRY_DELAY_KEY</code></li>
<li><code>int DEFAULT_MESOS_ARTIFACT_SERVER_PORT</code></li>
<li><code>boolean DEFAULT_SECURITY_SSL_VERIFY_HOSTNAME</code></li>
<li><code>java.lang.String CONTAINERIZED_HEAP_CUTOFF_MIN</code></li>
<li><code>java.lang.String YARN_HEARTBEAT_DELAY_SECONDS</code></li>
<li><code>java.lang.String AKKA_SSL_ENABLED</code></li>
<li><code>java.lang.String HA_MODE</code></li>
<li><code>java.lang.String ZOOKEEPER_MESOS_WORKERS_PATH</code></li>
<li><code>boolean DEFAULT_ZOOKEEPER_SASL_DISABLE</code></li>
<li><code>java.lang.String METRICS_SCOPE_DELIMITER</code></li>
<li><code>java.lang.String LOCAL_NUMBER_RESOURCE_MANAGER</code></li>
<li><code>java.lang.String AKKA_TCP_TIMEOUT</code></li>
<li><code>java.lang.String METRICS_SCOPE_NAMING_OPERATOR</code></li>
<li><code>java.lang.String ZOOKEEPER_RECOVERY_PATH</code></li>
<li><code>int DEFAULT_ZOOKEEPER_LEADER_PORT</code></li>
<li><code>java.lang.String DEFAULT_ZOOKEEPER_LATCH_PATH</code></li>
<li><code>int DEFAULT_ZOOKEEPER_PEER_PORT</code></li>
<li><code>java.lang.String METRICS_SCOPE_NAMING_TM_JOB</code></li>
<li><code>int DEFAULT_JOB_MANAGER_WEB_BACK_PRESSURE_NUM_SAMPLES</code></li>
<li><code>java.lang.String HA_ZOOKEEPER_SESSION_TIMEOUT</code></li>
<li><code>java.lang.String FLINK_JVM_OPTIONS</code></li>
<li><code>java.lang.String HA_ZOOKEEPER_CHECKPOINT_COUNTER_PATH</code></li>
<li><code>java.lang.String METRICS_SCOPE_NAMING_JM</code></li>
<li><code>java.lang.String DEFAULT_YARN_JOB_MANAGER_PORT</code></li>
<li><code>boolean DEFAULT_JOB_MANAGER_WEB_CHECKPOINTS_DISABLE</code></li>
<li><code>java.lang.String HA_ZOOKEEPER_QUORUM_KEY</code></li>
<li><code>boolean DEFAULT_JOB_MANAGER_WEB_SUBMIT_ENABLED</code></li>
<li><code>java.lang.String JOB_MANAGER_WEB_CHECKPOINTS_HISTORY_SIZE</code></li>
<li><code>java.lang.String ZOOKEEPER_JOBGRAPHS_PATH</code></li>
<li><code>java.lang.String ZOOKEEPER_SASL_SERVICE_NAME</code></li>
<li><code>java.lang.String DEFAULT_AKKA_LOOKUP_TIMEOUT</code></li>
<li><code>java.lang.String RESTART_STRATEGY_FAILURE_RATE_MAX_FAILURES_PER_INTERVAL</code></li>
<li><code>java.lang.String JOB_MANAGER_WEB_PORT_KEY</code></li>
<li><code>java.lang.String METRICS_LATENCY_HISTORY_SIZE</code></li>
<li><code>int DEFAULT_BLOB_FETCH_BACKLOG</code></li>
<li><code>java.lang.String JOB_MANAGER_WEB_BACK_PRESSURE_REFRESH_INTERVAL</code></li>
<li><code>float DEFAULT_SORT_SPILLING_THRESHOLD</code></li>
<li><code>java.lang.String DEFAULT_AKKA_TRANSPORT_HEARTBEAT_INTERVAL</code></li>
<li><code>java.lang.String CONTAINERIZED_MASTER_ENV_PREFIX</code></li>
<li><code>int DEFAULT_JOB_MANAGER_WEB_ARCHIVE_COUNT</code></li>
<li><code>java.lang.String TASK_MANAGER_HOSTNAME_KEY</code></li>
<li><code>java.lang.String AKKA_WATCH_HEARTBEAT_INTERVAL</code></li>
<li><code>java.lang.String DEFAULT_TASK_MANAGER_TMP_PATH</code></li>
<li><code>int DEFAULT_EXECUTION_RETRIES</code></li>
<li><code>int DEFAULT_JOB_MANAGER_WEB_FRONTEND_PORT</code></li>
<li><code>java.lang.String JOB_MANAGER_WEB_LOG_PATH_KEY</code></li>
<li><code>java.lang.String TASK_MANAGER_MEMORY_SIZE_KEY</code></li>
<li><code>java.lang.String DEFAULT_MESOS_RESOURCEMANAGER_FRAMEWORK_NAME</code></li>
<li><code>java.lang.String TASK_MANAGER_DATA_PORT_KEY</code></li>
<li><code>java.lang.String ZOOKEEPER_CHECKPOINTS_PATH</code></li>
<li><code>java.lang.String HA_JOB_MANAGER_PORT</code></li>
<li><code>java.lang.String TASK_MANAGER_REFUSED_REGISTRATION_PAUSE</code></li>
<li><code>java.lang.String CONTAINERIZED_HEAP_CUTOFF_RATIO</code></li>
<li><code>java.lang.String DEFAULT_SORT_SPILLING_THRESHOLD_KEY</code></li>
<li><code>java.lang.String YARN_CONTAINER_START_COMMAND_TEMPLATE</code></li>
<li><code>boolean DEFAULT_JOB_MANAGER_WEB_SSL_ENABLED</code></li>
<li><code>java.lang.String LIBRARY_CACHE_MANAGER_CLEANUP_INTERVAL</code></li>
<li><code>java.lang.String JOB_MANAGER_WEB_CHECKPOINTS_DISABLE</code></li>
<li><code>java.lang.String DEFAULT_ZOOKEEPER_LEADER_PATH</code></li>
<li><code>int DEFAULT_JOB_MANAGER_WEB_BACK_PRESSURE_DELAY</code></li>
<li><code>java.lang.String DEFAULT_TASK_MANAGER_MAX_REGISTRATION_PAUSE</code></li>
<li><code>java.lang.String METRICS_REPORTERS_LIST</code></li>
<li><code>java.lang.String DEFAULT_RECOVERY_MODE</code></li>
<li><code>int DEFAULT_METRICS_LATENCY_HISTORY_SIZE</code></li>
<li><code>java.lang.String TASK_MANAGER_INITIAL_REGISTRATION_PAUSE</code></li>
<li><code>java.lang.String DEFAULT_MESOS_RESOURCEMANAGER_FRAMEWORK_ROLE</code></li>
<li><code>int DEFAULT_JOB_MANAGER_WEB_CHECKPOINTS_HISTORY_SIZE</code></li>
<li><code>java.lang.String YARN_PROPERTIES_FILE_LOCATION</code></li>
<li><code>java.lang.String RECOVERY_JOB_MANAGER_PORT</code></li>
<li><code>boolean DEFAULT_SECURITY_SSL_ENABLED</code></li>
<li><code>java.lang.String MESOS_FAILOVER_TIMEOUT_SECONDS</code></li>
<li><code>java.lang.String RUNTIME_HASH_JOIN_BLOOM_FILTERS_KEY</code></li>
<li><code>java.lang.String ZOOKEEPER_LEADER_PATH</code></li>
<li><code>java.lang.String ZOOKEEPER_MAX_RETRY_ATTEMPTS</code></li>
<li><code>java.lang.String HA_ZOOKEEPER_CHECKPOINTS_PATH</code></li>
<li><code>java.lang.String MESOS_RESOURCEMANAGER_FRAMEWORK_ROLE</code></li>
<li><code>int DEFAULT_JOB_MANAGER_WEB_BACK_PRESSURE_REFRESH_INTERVAL</code></li>
<li><code>java.lang.String DEFAULT_ZOOKEEPER_MESOS_WORKERS_PATH</code></li>
<li><code>java.lang.String JOB_MANAGER_IPC_PORT_KEY</code></li>
<li><code>java.lang.String AKKA_WATCH_HEARTBEAT_PAUSE</code></li>
<li><code>java.lang.String MESOS_RESOURCEMANAGER_FRAMEWORK_NAME</code></li>
<li><code>java.lang.String DELIMITED_FORMAT_MAX_SAMPLE_LENGTH_KEY</code></li>
<li><code>java.lang.String STATE_BACKEND</code></li>
<li><code>java.lang.String MESOS_RESOURCEMANAGER_FRAMEWORK_PRINCIPAL</code></li>
<li><code>long DEFAULT_TASK_MANAGER_DEBUG_MEMORY_USAGE_LOG_INTERVAL_MS</code></li>
<li><code>java.lang.String DEFAULT_AKKA_CLIENT_TIMEOUT</code></li>
<li><code>int DEFAULT_SPILLING_MAX_FAN</code></li>
<li><code>java.lang.String TASK_MANAGER_IPC_PORT_KEY</code></li>
<li><code>java.lang.String TASK_MANAGER_MEMORY_OFF_HEAP_KEY</code></li>
<li><code>boolean DEFAULT_FILESYSTEM_OVERWRITE</code></li>
<li><code>boolean DEFAULT_USE_LARGE_RECORD_HANDLER</code></li>
<li><code>java.lang.String HA_ZOOKEEPER_JOBGRAPHS_PATH</code></li>
<li><code>boolean DEFAULT_BLOB_SERVICE_SSL_ENABLED</code></li>
<li><code>java.lang.String ZOOKEEPER_SESSION_TIMEOUT</code></li>
<li><code>java.lang.String TASK_MANAGER_NETWORK_DEFAULT_IO_MODE</code></li>
<li><code>java.lang.String SECURITY_SSL_TRUSTSTORE_PASSWORD</code></li>
<li><code>int DEFAULT_ZOOKEEPER_MAX_RETRY_ATTEMPTS</code></li>
<li><code>java.lang.String AKKA_STARTUP_TIMEOUT</code></li>
<li><code>java.lang.String TASK_MANAGER_TMP_DIR_KEY</code></li>
<li><code>java.lang.String USE_LARGE_RECORD_HANDLER_KEY</code></li>
<li><code>java.lang.String DEFAULT_ZOOKEEPER_DIR_KEY</code></li>
<li><code>int DEFAULT_YARN_MIN_HEAP_CUTOFF</code></li>
<li><code>java.lang.String TASK_MANAGER_DATA_SSL_ENABLED</code></li>
<li><code>java.lang.String HDFS_DEFAULT_CONFIG</code></li>
<li><code>boolean DEFAULT_TASK_MANAGER_DATA_SSL_ENABLED</code></li>
<li><code>java.lang.String DEFAULT_ZOOKEEPER_JOBGRAPHS_PATH</code></li>
<li><code>java.lang.String HA_ZOOKEEPER_MESOS_WORKERS_PATH</code></li>
<li><code>java.lang.String BLOB_STORAGE_DIRECTORY_KEY</code></li>
<li><code>java.lang.String DEFAULT_STATE_BACKEND</code></li>
<li><code>java.lang.String HA_ZOOKEEPER_RETRY_WAIT</code></li>
<li><code>java.lang.String AKKA_ASK_TIMEOUT</code></li>
<li><code>java.lang.String JOB_MANAGER_WEB_SUBMIT_ENABLED_KEY</code></li>
<li><code>java.lang.String DEFAULT_ZOOKEEPER_NAMESPACE_KEY</code></li>
<li><code>java.lang.String DEFAULT_ZOOKEEPER_CHECKPOINTS_PATH</code></li>
<li><code>int DEFAULT_LOCAL_NUMBER_JOB_MANAGER</code></li>
<li><code>java.lang.String AKKA_TRANSPORT_HEARTBEAT_INTERVAL</code></li>
<li><code>java.lang.String DEFAULT_ZOOKEEPER_CHECKPOINT_COUNTER_PATH</code></li>
<li><code>java.lang.String FS_STREAM_OPENING_TIMEOUT_KEY</code></li>
<li><code>java.lang.String SECURITY_SSL_TRUSTSTORE</code></li>
<li><code>java.lang.String METRICS_SCOPE_NAMING_JM_JOB</code></li>
<li><code>java.lang.String MESOS_INITIAL_TASKS</code></li>
<li><code>java.lang.String AKKA_FRAMESIZE</code></li>
<li><code>int DEFAULT_ZOOKEEPER_INIT_LIMIT</code></li>
<li><code>java.lang.String JOB_MANAGER_WEB_BACK_PRESSURE_CLEAN_UP_INTERVAL</code></li>
<li><code>java.lang.String SECURITY_SSL_KEYSTORE</code></li>
<li><code>boolean DEFAULT_MESOS_ARTIFACT_SERVER_SSL_ENABLED</code></li>
<li><code>java.lang.String HA_ZOOKEEPER_MAX_RETRY_ATTEMPTS</code></li>
<li><code>int DEFAULT_PARALLELISM</code></li>
<li><code>java.lang.String RECOVERY_MODE</code></li>
<li><code>java.lang.String EXECUTION_RETRIES_KEY</code></li>
<li><code>java.lang.String METRICS_REPORTER_SCOPE_DELIMITER</code></li>
<li><code>java.lang.String LOCAL_START_WEBSERVER</code></li>
<li><code>java.lang.String LOCAL_NUMBER_JOB_MANAGER</code></li>
<li><code>java.lang.String RESTART_STRATEGY</code></li>
<li><code>java.lang.String ZOOKEEPER_QUORUM_KEY</code></li>
<li><code>int DEFAULT_MESOS_FAILOVER_TIMEOUT_SECS</code></li>
<li><code>boolean DEFAULT_TASK_MANAGER_MEMORY_PRE_ALLOCATE</code></li>
<li><code>int DEFAULT_LOCAL_NUMBER_RESOURCE_MANAGER</code></li>
<li><code>java.lang.String HA_ZOOKEEPER_CLIENT_ACL</code></li>
<li><code>java.lang.String METRICS_REPORTER_FACTORY_CLASS_SUFFIX</code></li>
<li><code>boolean DEFAULT_FILESYSTEM_ALWAYS_CREATE_DIRECTORY</code></li>
<li><code>java.lang.String BLOB_FETCH_CONCURRENT_KEY</code></li>
<li><code>java.lang.String FILESYSTEM_DEFAULT_OVERWRITE_KEY</code></li>
<li><code>java.lang.String RESOURCE_MANAGER_IPC_PORT_KEY</code></li>
<li><code>java.lang.String DEFAULT_AKKA_ASK_TIMEOUT</code></li>
<li><code>int DEFAULT_ZOOKEEPER_CLIENT_PORT</code></li>
<li><code>double DEFAULT_AKKA_TRANSPORT_THRESHOLD</code></li>
<li><code>java.lang.String DEFAULT_AKKA_FRAMESIZE</code></li>
<li><code>java.lang.String TASK_MANAGER_NUM_TASK_SLOTS</code></li>
<li><code>java.lang.String YARN_APPLICATION_MASTER_ENV_PREFIX</code></li>
<li><code>java.lang.String JOB_MANAGER_WEB_BACK_PRESSURE_DELAY</code></li>
<li><code>long DEFAULT_TASK_CANCELLATION_INTERVAL_MILLIS</code></li>
<li><code>java.lang.String TASK_MANAGER_MEMORY_PRE_ALLOCATE_KEY</code></li>
<li><code>java.lang.String FILESYSTEM_SCHEME</code></li>
<li><code>java.lang.String TASK_MANAGER_MAX_REGISTRATION_DURATION</code></li>
<li><code>java.lang.String HA_ZOOKEEPER_DIR_KEY</code></li>
<li><code>java.lang.String DEFAULT_MESOS_RESOURCEMANAGER_FRAMEWORK_USER</code></li>
<li><code>java.lang.String DEFAULT_FILESYSTEM_SCHEME</code></li>
<li><code>java.lang.String MESOS_RESOURCEMANAGER_FRAMEWORK_SECRET</code></li>
<li><code>int DEFAULT_DELIMITED_FORMAT_MAX_SAMPLE_LEN</code></li>
<li><code>java.lang.String ENV_FLINK_BIN_DIR</code></li>
<li><code>float DEFAULT_YARN_HEAP_CUTOFF_RATIO</code></li>
<li><code>java.lang.String SAVEPOINT_FS_DIRECTORY_KEY</code></li>
<li><code>java.lang.String AKKA_JVM_EXIT_ON_FATAL_ERROR</code></li>
<li><code>java.lang.String ZOOKEEPER_RETRY_WAIT</code></li>
<li><code>java.lang.String HA_ZOOKEEPER_NAMESPACE_KEY</code></li>
<li><code>java.lang.String ZOOKEEPER_CONNECTION_TIMEOUT</code></li>
<li><code>java.lang.String TASK_MANAGER_NETWORK_NUM_BUFFERS_KEY</code></li>
<li><code>java.lang.String JOB_MANAGER_WEB_ARCHIVE_COUNT</code></li>
<li><code>int DEFAULT_RESOURCE_MANAGER_IPC_PORT</code></li>
<li><code>int DEFAULT_JOB_MANAGER_WEB_BACK_PRESSURE_CLEAN_UP_INTERVAL</code></li>
<li><code>java.lang.String YARN_REALLOCATE_FAILED_CONTAINERS</code></li>
<li><code>java.lang.String SECURITY_SSL_KEYSTORE_PASSWORD</code></li>
<li><code>java.lang.String DEFAULT_HA_JOB_MANAGER_PORT</code></li>
<li><code>java.lang.String BLOB_FETCH_RETRIES_KEY</code></li>
<li><code>java.lang.String METRICS_REPORTER_EXCLUDED_VARIABLES</code></li>
<li><code>java.lang.String DEFAULT_SECURITY_SSL_PROTOCOL</code></li>
<li><code>java.lang.String RECOVERY_JOB_DELAY</code></li>
<li><code>java.lang.String TASK_CANCELLATION_INTERVAL_MILLIS</code></li>
<li><code>java.lang.String YARN_APPLICATION_MASTER_PORT</code></li>
<li><code>int DEFAULT_TASK_MANAGER_DATA_PORT</code></li>
<li><code>java.lang.String RESTART_STRATEGY_FAILURE_RATE_FAILURE_RATE_INTERVAL</code></li>
<li><code>java.lang.String YARN_TASK_MANAGER_ENV_PREFIX</code></li>
<li><code>int DEFAULT_DELIMITED_FORMAT_MIN_LINE_SAMPLES</code></li>
<li><code>java.lang.String AKKA_LOG_LIFECYCLE_EVENTS</code></li>
<li><code>boolean DEFAULT_AKKA_LOG_LIFECYCLE_EVENTS</code></li>
<li><code>java.lang.String SECURITY_SSL_ENABLED</code></li>
<li><code>int DEFAULT_DELIMITED_FORMAT_MAX_LINE_SAMPLES</code></li>
<li><code>java.lang.String LOCAL_NUMBER_TASK_MANAGER</code></li>
<li><code>java.lang.String DEFAULT_TASK_MANAGER_REFUSED_REGISTRATION_PAUSE</code></li>
<li><code>java.lang.String DEFAULT_SECURITY_SSL_ALGORITHMS</code></li>
<li><code>java.lang.String MESOS_MAX_FAILED_TASKS</code></li>
<li><code>int DEFAULT_TASK_MANAGER_IPC_PORT</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.String&gt; DEFAULT_JOB_MANAGER_WEB_FRONTEND_ADDRESS</code></li>
<li><code>java.lang.String SECURITY_SSL_ALGORITHMS</code></li>
<li><code>int DEFAULT_ZOOKEEPER_CONNECTION_TIMEOUT</code></li>
<li><code>java.lang.String YARN_HEAP_CUTOFF_RATIO</code></li>
<li><code>java.lang.String HA_ZOOKEEPER_LATCH_PATH</code></li>
<li><code>int DEFAULT_ZOOKEEPER_SESSION_TIMEOUT</code></li>
<li><code>java.lang.String DEFAULT_SPILLING_MAX_FAN_KEY</code></li>
<li><code>java.lang.String AKKA_WATCH_THRESHOLD</code></li>
<li><code>java.lang.String TASK_MANAGER_DEBUG_MEMORY_USAGE_LOG_INTERVAL_MS</code></li>
<li><code>java.lang.String HA_ZOOKEEPER_STORAGE_PATH</code></li>
<li><code>java.lang.String DEFAULT_BLOB_SERVER_PORT</code></li>
<li><code>java.lang.String AKKA_TRANSPORT_THRESHOLD</code></li>
<li><code>java.lang.String ZOOKEEPER_CHECKPOINT_COUNTER_PATH</code></li>
<li><code>boolean DEFAULT_RUNTIME_HASH_JOIN_BLOOM_FILTERS</code></li>
<li><code>int DEFAULT_BLOB_FETCH_CONCURRENT</code></li>
<li><code>java.lang.String BLOB_SERVER_PORT</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.String&gt; RESTART_STRATEGY_FIXED_DELAY_DELAY</code></li>
<li><code>java.lang.String METRICS_REPORTER_CLASS_SUFFIX</code></li>
<li><code>java.lang.String ZOOKEEPER_DIR_KEY</code></li>
<li><code>java.lang.String JOB_MANAGER_IPC_ADDRESS_KEY</code></li>
<li><code>int DEFAULT_TASK_MANAGER_NETWORK_NUM_BUFFERS</code></li>
<li><code>java.lang.String DEFAULT_AKKA_TRANSPORT_HEARTBEAT_PAUSE</code></li>
<li><code>java.lang.String MESOS_ARTIFACT_SERVER_SSL_ENABLED</code></li>
<li><code>java.lang.String RESTART_STRATEGY_FAILURE_RATE_DELAY</code></li>
<li><code>java.lang.String DELIMITED_FORMAT_MIN_LINE_SAMPLES_KEY</code></li>
<li><code>java.lang.String BLOB_FETCH_BACKLOG_KEY</code></li>
<li><code>java.lang.String FILESYSTEM_OUTPUT_ALWAYS_CREATE_DIRECTORY_KEY</code></li>
<li><code>java.lang.String DEFAULT_TASK_MANAGER_MAX_REGISTRATION_DURATION</code></li>
<li><code>java.lang.String TASK_MANAGER_LOG_PATH_KEY</code></li>
<li><code>java.lang.String DEFAULT_TASK_MANAGER_NETWORK_DEFAULT_IO_MODE</code></li>
<li><code>int DEFAULT_YARN_HEAP_CUTOFF</code></li>
<li><code>java.lang.String SECURITY_SSL_PROTOCOL</code></li>
<li><code>java.lang.String JOB_MANAGER_WEB_BACK_PRESSURE_NUM_SAMPLES</code></li>
<li><code>java.lang.String CHECKPOINTS_DIRECTORY_KEY</code></li>
<li><code>java.lang.String DELIMITED_FORMAT_MAX_LINE_SAMPLES_KEY</code></li>
<li><code>java.lang.String PATH_HADOOP_CONFIG</code></li>
<li><code>java.lang.String ZOOKEEPER_SASL_DISABLE</code></li>
<li><code>java.lang.String AKKA_LOOKUP_TIMEOUT</code></li>
<li><code>java.lang.String YARN_HEAP_CUTOFF_MIN</code></li>
<li><code>java.lang.String AKKA_CLIENT_TIMEOUT</code></li>
<li><code>int DEFAULT_ZOOKEEPER_SYNC_LIMIT</code></li>
<li><code>java.lang.String DEFAULT_HA_MODE</code></li>
<li><code>java.lang.String CONTAINERIZED_TASK_MANAGER_ENV_PREFIX</code></li>
<li><code>java.lang.String HA_ZOOKEEPER_CONNECTION_TIMEOUT</code></li>
<li><code>java.lang.String METRICS_REPORTER_ADDITIONAL_VARIABLES</code></li>
<li><code>java.lang.String MESOS_ARTIFACT_SERVER_PORT_KEY</code></li>
<li><code>java.lang.String TASK_MANAGER_DEBUG_MEMORY_USAGE_START_LOG_THREAD</code></li>
<li><code>java.lang.String TASK_MANAGER_MEMORY_SEGMENT_SIZE_KEY</code></li>
<li><code>java.lang.String YARN_APPLICATION_ATTEMPTS</code></li>
<li><code>java.lang.String AKKA_TRANSPORT_HEARTBEAT_PAUSE</code></li>
<li><code>java.lang.String DEFAULT_TASK_MANAGER_INITIAL_REGISTRATION_PAUSE</code></li>
<li><code>java.lang.String SECURITY_SSL_VERIFY_HOSTNAME</code></li>
<li><code>java.lang.String DEFAULT_PARALLELISM_KEY</code></li>
<li><code>java.lang.String AKKA_DISPATCHER_THROUGHPUT</code></li>
<li><code>java.lang.String TASK_MANAGER_MEMORY_FRACTION_KEY</code></li>
<li><code>java.lang.String JOB_MANAGER_WEB_UPLOAD_DIR_KEY</code></li>
<li><code>java.lang.String SECURITY_SSL_KEY_PASSWORD</code></li>
<li><code>int DEFAULT_BLOB_FETCH_RETRIES</code></li>
<li><code>java.lang.String MESOS_RESOURCEMANAGER_FRAMEWORK_USER</code></li>
<li><code>java.lang.String BLOB_SERVICE_SSL_ENABLED</code></li>
<li><code>java.lang.String DEFAULT_YARN_APPLICATION_MASTER_PORT</code></li>
<li><code>java.lang.String METRICS_SCOPE_NAMING_TM</code></li>
<li><code>java.lang.String TASK_MANAGER_MAX_REGISTARTION_PAUSE</code></li>
<li><code>long DEFAULT_LIBRARY_CACHE_MANAGER_CLEANUP_INTERVAL</code></li>
<li><code>int DEFAULT_FS_STREAM_OPENING_TIMEOUT</code></li>
<li><code>java.lang.String YARN_VCORES</code></li>
<li><code>java.lang.String YARN_MAX_FAILED_CONTAINERS</code></li>
<li><code>java.lang.String METRICS_REPORTER_INTERVAL_SUFFIX</code></li>
<li><code>java.lang.String DEFAULT_HA_ZOOKEEPER_CLIENT_ACL</code></li>
<li><code>float DEFAULT_MEMORY_MANAGER_MEMORY_FRACTION</code></li>
<li><code>java.lang.String SAVEPOINT_DIRECTORY_KEY</code></li>
<li><code>int DEFAULT_ZOOKEEPER_RETRY_WAIT</code></li>
<li><code>java.lang.String ZOOKEEPER_LATCH_PATH</code></li>
<li><code>java.lang.String DEFAULT_RECOVERY_JOB_MANAGER_PORT</code></li>
<li><code>boolean DEFAULT_TASK_MANAGER_DEBUG_MEMORY_USAGE_START_LOG_THREAD</code></li>
<li><code>boolean DEFAULT_AKKA_SSL_ENABLED</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.configuration.ConfigOption</code>
<ul>
<li>method removed:
<ul>
<li><code>java.lang.Iterable&lt;java.lang.String&gt; deprecatedKeys()</code></li>
<li><code>boolean hasDeprecatedKeys()</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.configuration.ConfigOptions$OptionBuilder</code>
<ul>
<li>method removed:
<ul>
<li><code>org.apache.flink.configuration.ConfigOption&lt;T&gt; defaultValue(java.lang.Object)</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.String&gt; noDefaultValue()</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.configuration.Configuration</code>
<ul>
<li>method removed:
<ul>
<li><code>boolean getBoolean(java.lang.String, boolean)</code></li>
<li><code>boolean getBoolean(org.apache.flink.configuration.ConfigOption&lt;java.lang.Boolean&gt;)</code></li>
<li><code>boolean getBoolean(org.apache.flink.configuration.ConfigOption&lt;java.lang.Boolean&gt;, boolean)</code></li>
<li><code>byte[] getBytes(java.lang.String, byte[])</code></li>
<li><code>java.lang.Class&lt;T&gt; getClass(java.lang.String, java.lang.Class&lt;? extends T&gt;, java.lang.ClassLoader)</code></li>
<li><code>double getDouble(java.lang.String, double)</code></li>
<li><code>double getDouble(org.apache.flink.configuration.ConfigOption&lt;java.lang.Double&gt;)</code></li>
<li><code>double getDouble(org.apache.flink.configuration.ConfigOption&lt;java.lang.Double&gt;, double)</code></li>
<li><code>float getFloat(java.lang.String, float)</code></li>
<li><code>float getFloat(org.apache.flink.configuration.ConfigOption&lt;java.lang.Float&gt;)</code></li>
<li><code>float getFloat(org.apache.flink.configuration.ConfigOption&lt;java.lang.Float&gt;, float)</code></li>
<li><code>int getInteger(java.lang.String, int)</code></li>
<li><code>int getInteger(org.apache.flink.configuration.ConfigOption&lt;java.lang.Integer&gt;)</code></li>
<li><code>int getInteger(org.apache.flink.configuration.ConfigOption&lt;java.lang.Integer&gt;, int)</code></li>
<li><code>long getLong(java.lang.String, long)</code></li>
<li><code>long getLong(org.apache.flink.configuration.ConfigOption&lt;java.lang.Long&gt;)</code></li>
<li><code>long getLong(org.apache.flink.configuration.ConfigOption&lt;java.lang.Long&gt;, long)</code></li>
<li><code>java.lang.String getString(org.apache.flink.configuration.ConfigOption&lt;java.lang.String&gt;)</code></li>
<li><code>java.lang.String getString(org.apache.flink.configuration.ConfigOption&lt;java.lang.String&gt;, java.lang.String)</code></li>
<li><code>void setBoolean(java.lang.String, boolean)</code></li>
<li><code>void setBoolean(org.apache.flink.configuration.ConfigOption&lt;java.lang.Boolean&gt;, boolean)</code></li>
<li><code>void setBytes(java.lang.String, byte[])</code></li>
<li><code>void setClass(java.lang.String, java.lang.Class&lt;?&gt;)</code></li>
<li><code>void setDouble(java.lang.String, double)</code></li>
<li><code>void setDouble(org.apache.flink.configuration.ConfigOption&lt;java.lang.Double&gt;, double)</code></li>
<li><code>void setFloat(java.lang.String, float)</code></li>
<li><code>void setFloat(org.apache.flink.configuration.ConfigOption&lt;java.lang.Float&gt;, float)</code></li>
<li><code>void setInteger(java.lang.String, int)</code></li>
<li><code>void setInteger(org.apache.flink.configuration.ConfigOption&lt;java.lang.Integer&gt;, int)</code></li>
<li><code>void setLong(java.lang.String, long)</code></li>
<li><code>void setLong(org.apache.flink.configuration.ConfigOption&lt;java.lang.Long&gt;, long)</code></li>
<li><code>void setString(org.apache.flink.configuration.ConfigOption&lt;java.lang.String&gt;, java.lang.String)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.configuration.HighAvailabilityOptions</code>
<ul>
<li>field removed:
<ul>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.String&gt; ZOOKEEPER_RUNNING_JOB_REGISTRY_PATH</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.String&gt; HA_JOB_DELAY</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.configuration.JobManagerOptions</code>
<ul>
<li>field removed:
<ul>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.Integer&gt; JOB_MANAGER_HEAP_MEMORY_MB</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.time.Duration&gt; BLOCK_SLOW_NODE_DURATION</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;org.apache.flink.configuration.MemorySize&gt; ADAPTIVE_BATCH_SCHEDULER_AVG_DATA_VOLUME_PER_TASK</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.Integer&gt; SPECULATIVE_MAX_CONCURRENT_EXECUTIONS</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.Integer&gt; ADAPTIVE_BATCH_SCHEDULER_DEFAULT_SOURCE_PARALLELISM</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.Integer&gt; ADAPTIVE_BATCH_SCHEDULER_MAX_PARALLELISM</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;org.apache.flink.configuration.MemorySize&gt; JOB_MANAGER_HEAP_MEMORY</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.Integer&gt; ADAPTIVE_BATCH_SCHEDULER_MIN_PARALLELISM</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.Boolean&gt; SPECULATIVE_ENABLED</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.configuration.JobManagerOptions$SchedulerType</code>
<ul>
<li>field removed:
<ul>
<li><code>org.apache.flink.configuration.JobManagerOptions$SchedulerType Ng</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.configuration.MetricOptions</code>
<ul>
<li>field removed:
<ul>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.String&gt; REPORTER_CLASS</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.configuration.NettyShuffleEnvironmentOptions</code>
<ul>
<li>field removed:
<ul>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.Integer&gt; NUM_THREADS_CLIENT</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.Integer&gt; NETWORK_BUFFERS_PER_CHANNEL</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.Integer&gt; HYBRID_SHUFFLE_SPILLED_INDEX_REGION_GROUP_SIZE</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.Integer&gt; CONNECT_BACKLOG</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.Boolean&gt; NETWORK_HYBRID_SHUFFLE_ENABLE_NEW_MODE</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.Float&gt; NETWORK_BUFFERS_MEMORY_FRACTION</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.Integer&gt; NUM_ARENAS</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.Integer&gt; NUM_THREADS_SERVER</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.Long&gt; HYBRID_SHUFFLE_NUM_RETAINED_IN_MEMORY_REGIONS_MAX</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.String&gt; NETWORK_BUFFERS_MEMORY_MIN</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.String&gt; TRANSPORT_TYPE</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.String&gt; NETWORK_BLOCKING_SHUFFLE_TYPE</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.Integer&gt; NETWORK_MAX_OVERDRAFT_BUFFERS_PER_GATE</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.Long&gt; NETWORK_EXCLUSIVE_BUFFERS_REQUEST_TIMEOUT_MILLISECONDS</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.Boolean&gt; BATCH_SHUFFLE_COMPRESSION_ENABLED</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.Integer&gt; SEND_RECEIVE_BUFFER_SIZE</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.String&gt; NETWORK_BUFFERS_MEMORY_MAX</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.Integer&gt; NETWORK_EXTRA_BUFFERS_PER_GATE</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.Integer&gt; NETWORK_SORT_SHUFFLE_MIN_PARALLELISM</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.Integer&gt; NETWORK_NUM_BUFFERS</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.Integer&gt; NETWORK_MAX_BUFFERS_PER_CHANNEL</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.Integer&gt; MAX_NUM_TCP_CONNECTIONS</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.configuration.PipelineOptions</code>
<ul>
<li>field removed:
<ul>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.util.List&lt;java.lang.String&gt;&gt; KRYO_DEFAULT_SERIALIZERS</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.util.List&lt;java.lang.String&gt;&gt; POJO_REGISTERED_CLASSES</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.Boolean&gt; AUTO_TYPE_REGISTRATION</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.util.List&lt;java.lang.String&gt;&gt; KRYO_REGISTERED_CLASSES</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.configuration.ResourceManagerOptions</code>
<ul>
<li>field removed:
<ul>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.Integer&gt; LOCAL_NUMBER_RESOURCE_MANAGER</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.Boolean&gt; TASK_MANAGER_RELEASE_WHEN_RESULT_CONSUMED</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.Long&gt; SLOT_MANAGER_TASK_MANAGER_TIMEOUT</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.configuration.SecurityOptions</code>
<ul>
<li>field removed:
<ul>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.Double&gt; KERBEROS_TOKENS_RENEWAL_TIME_RATIO</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.time.Duration&gt; KERBEROS_TOKENS_RENEWAL_RETRY_BACKOFF</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.Boolean&gt; KERBEROS_FETCH_DELEGATION_TOKEN</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.Boolean&gt; SSL_ENABLED</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.configuration.StateBackendOptions</code>
<ul>
<li>field removed:
<ul>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.Integer&gt; LATENCY_TRACK_HISTORY_SIZE</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.Boolean&gt; LATENCY_TRACK_STATE_NAME_AS_VARIABLE</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.Boolean&gt; LATENCY_TRACK_ENABLED</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.Integer&gt; LATENCY_TRACK_SAMPLE_INTERVAL</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.configuration.TaskManagerOptions</code>
<ul>
<li>field removed:
<ul>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.time.Duration&gt; REGISTRATION_MAX_BACKOFF</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.time.Duration&gt; INITIAL_REGISTRATION_BACKOFF</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.Boolean&gt; EXIT_ON_FATAL_AKKA_ERROR</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.Integer&gt; TASK_MANAGER_HEAP_MEMORY_MB</code></li>
<li><code>java.lang.String MANAGED_MEMORY_CONSUMER_NAME_DATAPROC</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;org.apache.flink.configuration.MemorySize&gt; TASK_MANAGER_HEAP_MEMORY</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.time.Duration&gt; REFUSED_REGISTRATION_BACKOFF</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.configuration.TaskManagerOptions$TaskManagerLoadBalanceMode</code>
<ul>
<li>method removed:
<ul>
<li><code>org.apache.flink.configuration.TaskManagerOptions$TaskManagerLoadBalanceMode loadFromConfiguration(org.apache.flink.configuration.Configuration)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.configuration.WebOptions</code>
<ul>
<li>field removed:
<ul>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.Integer&gt; BACKPRESSURE_DELAY</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.Integer&gt; PORT</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.Integer&gt; BACKPRESSURE_REFRESH_INTERVAL</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.Integer&gt; BACKPRESSURE_NUM_SAMPLES</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.String&gt; ADDRESS</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.Integer&gt; BACKPRESSURE_CLEANUP_INTERVAL</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.Boolean&gt; SSL_ENABLED</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.connector.base.sink.AsyncSinkBase</code>
<ul>
<li>interface removed:
<ul>
<li><code>org.apache.flink.api.connector.sink2.StatefulSink</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.connector.base.sink.writer.AsyncSinkWriter</code>
<ul>
<li>constructor removed:
<ul>
<li><code>AsyncSinkWriter(org.apache.flink.connector.base.sink.writer.ElementConverter&lt;InputT,RequestEntryT&gt;, org.apache.flink.api.connector.sink2.Sink$InitContext, int, int, int, long, long, long)</code></li>
<li><code>AsyncSinkWriter(org.apache.flink.connector.base.sink.writer.ElementConverter&lt;InputT,RequestEntryT&gt;, org.apache.flink.api.connector.sink2.Sink$InitContext, int, int, int, long, long, long, java.util.Collection&lt;org.apache.flink.connector.base.sink.writer.BufferedRequestState&lt;RequestEntryT&gt;&gt;)</code></li>
<li><code>AsyncSinkWriter(org.apache.flink.connector.base.sink.writer.ElementConverter&lt;InputT,RequestEntryT&gt;, org.apache.flink.api.connector.sink2.Sink$InitContext, org.apache.flink.connector.base.sink.writer.config.AsyncSinkWriterConfiguration, java.util.Collection&lt;org.apache.flink.connector.base.sink.writer.BufferedRequestState&lt;RequestEntryT&gt;&gt;)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.connector.base.sink.writer.ElementConverter</code>
<ul>
<li>method removed:
<ul>
<li><code>void open(org.apache.flink.api.connector.sink2.Sink$InitContext)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.connector.base.source.reader.fetcher.SingleThreadFetcherManager</code>
<ul>
<li>constructor removed:
<ul>
<li><code>SingleThreadFetcherManager(org.apache.flink.connector.base.source.reader.synchronization.FutureCompletingBlockingQueue&lt;org.apache.flink.connector.base.source.reader.RecordsWithSplitIds&lt;E&gt;&gt;, java.util.function.Supplier&lt;org.apache.flink.connector.base.source.reader.splitreader.SplitReader&lt;E,SplitT&gt;&gt;)</code></li>
<li><code>SingleThreadFetcherManager(org.apache.flink.connector.base.source.reader.synchronization.FutureCompletingBlockingQueue&lt;org.apache.flink.connector.base.source.reader.RecordsWithSplitIds&lt;E&gt;&gt;, java.util.function.Supplier&lt;org.apache.flink.connector.base.source.reader.splitreader.SplitReader&lt;E,SplitT&gt;&gt;, org.apache.flink.configuration.Configuration)</code></li>
<li><code>SingleThreadFetcherManager(org.apache.flink.connector.base.source.reader.synchronization.FutureCompletingBlockingQueue&lt;org.apache.flink.connector.base.source.reader.RecordsWithSplitIds&lt;E&gt;&gt;, java.util.function.Supplier&lt;org.apache.flink.connector.base.source.reader.splitreader.SplitReader&lt;E,SplitT&gt;&gt;, org.apache.flink.configuration.Configuration, java.util.function.Consumer&lt;java.util.Collection&lt;java.lang.String&gt;&gt;)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager</code>
<ul>
<li>constructor removed:
<ul>
<li><code>SplitFetcherManager(org.apache.flink.connector.base.source.reader.synchronization.FutureCompletingBlockingQueue&lt;org.apache.flink.connector.base.source.reader.RecordsWithSplitIds&lt;E&gt;&gt;, java.util.function.Supplier&lt;org.apache.flink.connector.base.source.reader.splitreader.SplitReader&lt;E,SplitT&gt;&gt;, org.apache.flink.configuration.Configuration, java.util.function.Consumer&lt;java.util.Collection&lt;java.lang.String&gt;&gt;)</code></li>
<li><code>SplitFetcherManager(org.apache.flink.connector.base.source.reader.synchronization.FutureCompletingBlockingQueue&lt;org.apache.flink.connector.base.source.reader.RecordsWithSplitIds&lt;E&gt;&gt;, java.util.function.Supplier&lt;org.apache.flink.connector.base.source.reader.splitreader.SplitReader&lt;E,SplitT&gt;&gt;, org.apache.flink.configuration.Configuration)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.connector.base.source.reader.SingleThreadMultiplexSourceReaderBase</code>
<ul>
<li>constructor removed:
<ul>
<li><code>SingleThreadMultiplexSourceReaderBase(org.apache.flink.connector.base.source.reader.synchronization.FutureCompletingBlockingQueue&lt;org.apache.flink.connector.base.source.reader.RecordsWithSplitIds&lt;E&gt;&gt;, java.util.function.Supplier&lt;org.apache.flink.connector.base.source.reader.splitreader.SplitReader&lt;E,SplitT&gt;&gt;, org.apache.flink.connector.base.source.reader.RecordEmitter&lt;E,T,SplitStateT&gt;, org.apache.flink.configuration.Configuration, org.apache.flink.api.connector.source.SourceReaderContext)</code></li>
<li><code>SingleThreadMultiplexSourceReaderBase(org.apache.flink.connector.base.source.reader.synchronization.FutureCompletingBlockingQueue&lt;org.apache.flink.connector.base.source.reader.RecordsWithSplitIds&lt;E&gt;&gt;, org.apache.flink.connector.base.source.reader.fetcher.SingleThreadFetcherManager&lt;E,SplitT&gt;, org.apache.flink.connector.base.source.reader.RecordEmitter&lt;E,T,SplitStateT&gt;, org.apache.flink.configuration.Configuration, org.apache.flink.api.connector.source.SourceReaderContext)</code></li>
<li><code>SingleThreadMultiplexSourceReaderBase(org.apache.flink.connector.base.source.reader.synchronization.FutureCompletingBlockingQueue&lt;org.apache.flink.connector.base.source.reader.RecordsWithSplitIds&lt;E&gt;&gt;, org.apache.flink.connector.base.source.reader.fetcher.SingleThreadFetcherManager&lt;E,SplitT&gt;, org.apache.flink.connector.base.source.reader.RecordEmitter&lt;E,T,SplitStateT&gt;, org.apache.flink.connector.base.source.reader.RecordEvaluator&lt;T&gt;, org.apache.flink.configuration.Configuration, org.apache.flink.api.connector.source.SourceReaderContext)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.connector.base.source.reader.SourceReaderBase</code>
<ul>
<li>constructor removed:
<ul>
<li><code>SourceReaderBase(org.apache.flink.connector.base.source.reader.synchronization.FutureCompletingBlockingQueue&lt;org.apache.flink.connector.base.source.reader.RecordsWithSplitIds&lt;E&gt;&gt;, org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager&lt;E,SplitT&gt;, org.apache.flink.connector.base.source.reader.RecordEmitter&lt;E,T,SplitStateT&gt;, org.apache.flink.configuration.Configuration, org.apache.flink.api.connector.source.SourceReaderContext)</code></li>
<li><code>SourceReaderBase(org.apache.flink.connector.base.source.reader.synchronization.FutureCompletingBlockingQueue&lt;org.apache.flink.connector.base.source.reader.RecordsWithSplitIds&lt;E&gt;&gt;, org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager&lt;E,SplitT&gt;, org.apache.flink.connector.base.source.reader.RecordEmitter&lt;E,T,SplitStateT&gt;, org.apache.flink.connector.base.source.reader.RecordEvaluator&lt;T&gt;, org.apache.flink.configuration.Configuration, org.apache.flink.api.connector.source.SourceReaderContext)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.core.execution.JobClient</code>
<ul>
<li>method removed:
<ul>
<li><code>java.util.concurrent.CompletableFuture&lt;java.lang.String&gt; stopWithSavepoint(boolean, java.lang.String)</code></li>
<li><code>java.util.concurrent.CompletableFuture&lt;java.lang.String&gt; triggerSavepoint(java.lang.String)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.core.failure.FailureEnricher$Context</code>
<ul>
<li>method removed:
<ul>
<li><code>org.apache.flink.api.common.JobID getJobId()</code></li>
<li><code>java.lang.String getJobName()</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.core.fs.FileSystem</code>
<ul>
<li>method removed:
<ul>
<li><code>org.apache.flink.core.fs.FileSystemKind getKind()</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.core.fs.Path</code>
<ul>
<li>interface removed:
<ul>
<li><code>org.apache.flink.core.io.IOReadableWritable</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.datastream.api.stream.KeyedPartitionStream</code>
<ul>
<li>method modified:
<ul>
<li><code>org.apache.flink.datastream.api.stream.KeyedPartitionStream$ProcessConfigurableAndTwoKeyedPartitionStreams&lt;K,OUT1,OUT2&gt;&lt;K,OUT1,OUT2&gt; (&lt;-org.apache.flink.datastream.api.stream.KeyedPartitionStream$TwoKeyedPartitionStreams&lt;K,OUT1,OUT2&gt;&lt;K,OUT1,OUT2&gt;) process(org.apache.flink.datastream.api.function.TwoOutputStreamProcessFunction&lt;T,OUT1,OUT2&gt;&lt;T,OUT1,OUT2&gt;, org.apache.flink.api.java.functions.KeySelector&lt;OUT1,K&gt;&lt;OUT1,K&gt;, org.apache.flink.api.java.functions.KeySelector&lt;OUT2,K&gt;&lt;OUT2,K&gt;)</code></li>
<li><code>org.apache.flink.datastream.api.stream.NonKeyedPartitionStream$ProcessConfigurableAndTwoNonKeyedPartitionStream&lt;OUT1,OUT2&gt;&lt;OUT1,OUT2&gt; (&lt;-org.apache.flink.datastream.api.stream.NonKeyedPartitionStream$TwoNonKeyedPartitionStreams&lt;OUT1,OUT2&gt;&lt;OUT1,OUT2&gt;) process(org.apache.flink.datastream.api.function.TwoOutputStreamProcessFunction&lt;T,OUT1,OUT2&gt;&lt;T,OUT1,OUT2&gt;)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.datastream.api.stream.NonKeyedPartitionStream</code>
<ul>
<li>method modified:
<ul>
<li><code>org.apache.flink.datastream.api.stream.NonKeyedPartitionStream$ProcessConfigurableAndTwoNonKeyedPartitionStream&lt;OUT1,OUT2&gt;&lt;OUT1,OUT2&gt; (&lt;-org.apache.flink.datastream.api.stream.NonKeyedPartitionStream$TwoNonKeyedPartitionStreams&lt;OUT1,OUT2&gt;&lt;OUT1,OUT2&gt;) process(org.apache.flink.datastream.api.function.TwoOutputStreamProcessFunction&lt;T,OUT1,OUT2&gt;&lt;T,OUT1,OUT2&gt;)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.streaming.api.connector.sink2.CommittableMessage</code>
<ul>
<li>method removed:
<ul>
<li><code>java.util.OptionalLong getCheckpointId()</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.streaming.api.connector.sink2.CommittableSummary</code>
<ul>
<li>constructor removed:
<ul>
<li><code>CommittableSummary(int, int, java.lang.Long, int, int, int)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.streaming.api.connector.sink2.CommittableWithLineage</code>
<ul>
<li>constructor removed:
<ul>
<li><code>CommittableWithLineage(java.lang.Object, java.lang.Long, int)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.streaming.api.datastream.AllWindowedStream</code>
<ul>
<li>method removed:
<ul>
<li><code>org.apache.flink.streaming.api.datastream.AllWindowedStream&lt;T,W&gt; allowedLateness(org.apache.flink.streaming.api.windowing.time.Time)</code></li>
<li><code>org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator&lt;R&gt; apply(org.apache.flink.api.common.functions.ReduceFunction&lt;T&gt;, org.apache.flink.streaming.api.functions.windowing.AllWindowFunction&lt;T,R,W&gt;)</code></li>
<li><code>org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator&lt;R&gt; apply(org.apache.flink.api.common.functions.ReduceFunction&lt;T&gt;, org.apache.flink.streaming.api.functions.windowing.AllWindowFunction&lt;T,R,W&gt;, org.apache.flink.api.common.typeinfo.TypeInformation&lt;R&gt;)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.streaming.api.datastream.CoGroupedStreams$WithWindow</code>
<ul>
<li>method removed:
<ul>
<li><code>org.apache.flink.streaming.api.datastream.CoGroupedStreams$WithWindow&lt;T1,T2,KEY,W&gt; allowedLateness(org.apache.flink.streaming.api.windowing.time.Time)</code></li>
<li><code>org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator&lt;T&gt; with(org.apache.flink.api.common.functions.CoGroupFunction&lt;T1,T2,T&gt;)</code></li>
<li><code>org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator&lt;T&gt; with(org.apache.flink.api.common.functions.CoGroupFunction&lt;T1,T2,T&gt;, org.apache.flink.api.common.typeinfo.TypeInformation&lt;T&gt;)</code></li>
</ul>
</li>
<li>method modified:
<ul>
<li><code>org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator&lt;T&gt;&lt;T&gt; (&lt;-org.apache.flink.streaming.api.datastream.DataStream&lt;T&gt;&lt;T&gt;) apply(org.apache.flink.api.common.functions.CoGroupFunction&lt;T1,T2,T&gt;&lt;T1,T2,T&gt;)</code></li>
<li><code>org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator&lt;T&gt;&lt;T&gt; (&lt;-org.apache.flink.streaming.api.datastream.DataStream&lt;T&gt;&lt;T&gt;) apply(org.apache.flink.api.common.functions.CoGroupFunction&lt;T1,T2,T&gt;&lt;T1,T2,T&gt;, org.apache.flink.api.common.typeinfo.TypeInformation&lt;T&gt;&lt;T&gt;)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.streaming.api.datastream.DataStream</code>
<ul>
<li>method removed:
<ul>
<li><code>org.apache.flink.streaming.api.datastream.DataStreamSink&lt;T&gt; addSink(org.apache.flink.streaming.api.functions.sink.SinkFunction&lt;T&gt;)</code></li>
<li><code>org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator&lt;T&gt; assignTimestampsAndWatermarks(org.apache.flink.streaming.api.functions.AssignerWithPeriodicWatermarks&lt;T&gt;)</code></li>
<li><code>org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator&lt;T&gt; assignTimestampsAndWatermarks(org.apache.flink.streaming.api.functions.AssignerWithPunctuatedWatermarks&lt;T&gt;)</code></li>
<li><code>org.apache.flink.streaming.api.datastream.IterativeStream&lt;T&gt; iterate()</code></li>
<li><code>org.apache.flink.streaming.api.datastream.IterativeStream&lt;T&gt; iterate(long)</code></li>
<li><code>org.apache.flink.streaming.api.datastream.KeyedStream&lt;T,org.apache.flink.api.java.tuple.Tuple&gt; keyBy(int[])</code></li>
<li><code>org.apache.flink.streaming.api.datastream.KeyedStream&lt;T,org.apache.flink.api.java.tuple.Tuple&gt; keyBy(java.lang.String[])</code></li>
<li><code>org.apache.flink.streaming.api.datastream.DataStream&lt;T&gt; partitionCustom(org.apache.flink.api.common.functions.Partitioner&lt;K&gt;, int)</code></li>
<li><code>org.apache.flink.streaming.api.datastream.DataStream&lt;T&gt; partitionCustom(org.apache.flink.api.common.functions.Partitioner&lt;K&gt;, java.lang.String)</code></li>
<li><code>org.apache.flink.streaming.api.datastream.DataStreamSink&lt;T&gt; sinkTo(org.apache.flink.api.connector.sink.Sink&lt;T,?,?,?&gt;)</code></li>
<li><code>org.apache.flink.streaming.api.datastream.DataStreamSink&lt;T&gt; sinkTo(org.apache.flink.api.connector.sink.Sink&lt;T,?,?,?&gt;, org.apache.flink.streaming.api.datastream.CustomSinkOperatorUidHashes)</code></li>
<li><code>org.apache.flink.streaming.api.datastream.AllWindowedStream&lt;T,org.apache.flink.streaming.api.windowing.windows.TimeWindow&gt; timeWindowAll(org.apache.flink.streaming.api.windowing.time.Time)</code></li>
<li><code>org.apache.flink.streaming.api.datastream.AllWindowedStream&lt;T,org.apache.flink.streaming.api.windowing.windows.TimeWindow&gt; timeWindowAll(org.apache.flink.streaming.api.windowing.time.Time, org.apache.flink.streaming.api.windowing.time.Time)</code></li>
<li><code>org.apache.flink.streaming.api.datastream.DataStreamSink&lt;T&gt; writeAsCsv(java.lang.String)</code></li>
<li><code>org.apache.flink.streaming.api.datastream.DataStreamSink&lt;T&gt; writeAsCsv(java.lang.String, org.apache.flink.core.fs.FileSystem$WriteMode)</code></li>
<li><code>org.apache.flink.streaming.api.datastream.DataStreamSink&lt;T&gt; writeAsCsv(java.lang.String, org.apache.flink.core.fs.FileSystem$WriteMode, java.lang.String, java.lang.String)</code></li>
<li><code>org.apache.flink.streaming.api.datastream.DataStreamSink&lt;T&gt; writeAsText(java.lang.String)</code></li>
<li><code>org.apache.flink.streaming.api.datastream.DataStreamSink&lt;T&gt; writeAsText(java.lang.String, org.apache.flink.core.fs.FileSystem$WriteMode)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.streaming.api.datastream.DataStreamUtils</code>
<ul>
<li>method removed:
<ul>
<li><code>java.util.Iterator&lt;OUT&gt; collect(org.apache.flink.streaming.api.datastream.DataStream&lt;OUT&gt;)</code></li>
<li><code>java.util.Iterator&lt;OUT&gt; collect(org.apache.flink.streaming.api.datastream.DataStream&lt;OUT&gt;, java.lang.String)</code></li>
<li><code>java.util.List&lt;E&gt; collectBoundedStream(org.apache.flink.streaming.api.datastream.DataStream&lt;E&gt;, java.lang.String)</code></li>
<li><code>java.util.List&lt;E&gt; collectRecordsFromUnboundedStream(org.apache.flink.streaming.api.operators.collect.ClientAndIterator&lt;E&gt;, int)</code></li>
<li><code>java.util.List&lt;E&gt; collectUnboundedStream(org.apache.flink.streaming.api.datastream.DataStream&lt;E&gt;, int, java.lang.String)</code></li>
<li><code>org.apache.flink.streaming.api.operators.collect.ClientAndIterator&lt;OUT&gt; collectWithClient(org.apache.flink.streaming.api.datastream.DataStream&lt;OUT&gt;, java.lang.String)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.streaming.api.datastream.JoinedStreams$WithWindow</code>
<ul>
<li>method removed:
<ul>
<li><code>org.apache.flink.streaming.api.datastream.JoinedStreams$WithWindow&lt;T1,T2,KEY,W&gt; allowedLateness(org.apache.flink.streaming.api.windowing.time.Time)</code></li>
<li><code>org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator&lt;T&gt; with(org.apache.flink.api.common.functions.JoinFunction&lt;T1,T2,T&gt;)</code></li>
<li><code>org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator&lt;T&gt; with(org.apache.flink.api.common.functions.FlatJoinFunction&lt;T1,T2,T&gt;, org.apache.flink.api.common.typeinfo.TypeInformation&lt;T&gt;)</code></li>
<li><code>org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator&lt;T&gt; with(org.apache.flink.api.common.functions.FlatJoinFunction&lt;T1,T2,T&gt;)</code></li>
<li><code>org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator&lt;T&gt; with(org.apache.flink.api.common.functions.JoinFunction&lt;T1,T2,T&gt;, org.apache.flink.api.common.typeinfo.TypeInformation&lt;T&gt;)</code></li>
</ul>
</li>
<li>method modified:
<ul>
<li><code>org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator&lt;T&gt;&lt;T&gt; (&lt;-org.apache.flink.streaming.api.datastream.DataStream&lt;T&gt;&lt;T&gt;) apply(org.apache.flink.api.common.functions.JoinFunction&lt;T1,T2,T&gt;&lt;T1,T2,T&gt;)</code></li>
<li><code>org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator&lt;T&gt;&lt;T&gt; (&lt;-org.apache.flink.streaming.api.datastream.DataStream&lt;T&gt;&lt;T&gt;) apply(org.apache.flink.api.common.functions.FlatJoinFunction&lt;T1,T2,T&gt;&lt;T1,T2,T&gt;, org.apache.flink.api.common.typeinfo.TypeInformation&lt;T&gt;&lt;T&gt;)</code></li>
<li><code>org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator&lt;T&gt;&lt;T&gt; (&lt;-org.apache.flink.streaming.api.datastream.DataStream&lt;T&gt;&lt;T&gt;) apply(org.apache.flink.api.common.functions.FlatJoinFunction&lt;T1,T2,T&gt;&lt;T1,T2,T&gt;)</code></li>
<li><code>org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator&lt;T&gt;&lt;T&gt; (&lt;-org.apache.flink.streaming.api.datastream.DataStream&lt;T&gt;&lt;T&gt;) apply(org.apache.flink.api.common.functions.JoinFunction&lt;T1,T2,T&gt;&lt;T1,T2,T&gt;, org.apache.flink.api.common.typeinfo.TypeInformation&lt;T&gt;&lt;T&gt;)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.streaming.api.datastream.KeyedStream</code>
<ul>
<li>method removed:
<ul>
<li><code>org.apache.flink.streaming.api.datastream.WindowedStream&lt;T,KEY,org.apache.flink.streaming.api.windowing.windows.TimeWindow&gt; timeWindow(org.apache.flink.streaming.api.windowing.time.Time)</code></li>
<li><code>org.apache.flink.streaming.api.datastream.WindowedStream&lt;T,KEY,org.apache.flink.streaming.api.windowing.windows.TimeWindow&gt; timeWindow(org.apache.flink.streaming.api.windowing.time.Time, org.apache.flink.streaming.api.windowing.time.Time)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.streaming.api.datastream.KeyedStream$IntervalJoin</code>
<ul>
<li>method removed:
<ul>
<li><code>org.apache.flink.streaming.api.datastream.KeyedStream$IntervalJoined&lt;T1,T2,KEY&gt; between(org.apache.flink.streaming.api.windowing.time.Time, org.apache.flink.streaming.api.windowing.time.Time)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.streaming.api.datastream.WindowedStream</code>
<ul>
<li>method removed:
<ul>
<li><code>org.apache.flink.streaming.api.datastream.WindowedStream&lt;T,K,W&gt; allowedLateness(org.apache.flink.streaming.api.windowing.time.Time)</code></li>
<li><code>org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator&lt;R&gt; apply(org.apache.flink.api.common.functions.ReduceFunction&lt;T&gt;, org.apache.flink.streaming.api.functions.windowing.WindowFunction&lt;T,R,K,W&gt;)</code></li>
<li><code>org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator&lt;R&gt; apply(org.apache.flink.api.common.functions.ReduceFunction&lt;T&gt;, org.apache.flink.streaming.api.functions.windowing.WindowFunction&lt;T,R,K,W&gt;, org.apache.flink.api.common.typeinfo.TypeInformation&lt;R&gt;)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.streaming.api.environment.CheckpointConfig</code>
<ul>
<li>field removed:
<ul>
<li><code>int UNDEFINED_TOLERABLE_CHECKPOINT_NUMBER</code></li>
<li><code>long DEFAULT_TIMEOUT</code></li>
<li><code>long DEFAULT_MIN_PAUSE_BETWEEN_CHECKPOINTS</code></li>
<li><code>org.apache.flink.streaming.api.CheckpointingMode DEFAULT_MODE</code></li>
<li><code>int DEFAULT_MAX_CONCURRENT_CHECKPOINTS</code></li>
<li><code>int DEFAULT_CHECKPOINT_ID_OF_IGNORED_IN_FLIGHT_DATA</code></li>
</ul>
</li>
<li>method removed:
<ul>
<li><code>void enableExternalizedCheckpoints(org.apache.flink.streaming.api.environment.CheckpointConfig$ExternalizedCheckpointCleanup)</code></li>
<li><code>java.time.Duration getAlignmentTimeout()</code></li>
<li><code>org.apache.flink.runtime.state.CheckpointStorage getCheckpointStorage()</code></li>
<li><code>org.apache.flink.streaming.api.environment.CheckpointConfig$ExternalizedCheckpointCleanup getExternalizedCheckpointCleanup()</code></li>
<li><code>boolean isFailOnCheckpointingErrors()</code></li>
<li><code>boolean isForceCheckpointing()</code></li>
<li><code>void setAlignmentTimeout(java.time.Duration)</code></li>
<li><code>void setCheckpointStorage(org.apache.flink.runtime.state.CheckpointStorage)</code></li>
<li><code>void setCheckpointStorage(java.lang.String)</code></li>
<li><code>void setCheckpointStorage(java.net.URI)</code></li>
<li><code>void setCheckpointStorage(org.apache.flink.core.fs.Path)</code></li>
<li><code>void setExternalizedCheckpointCleanup(org.apache.flink.streaming.api.environment.CheckpointConfig$ExternalizedCheckpointCleanup)</code></li>
<li><code>void setFailOnCheckpointingErrors(boolean)</code></li>
<li><code>void setForceCheckpointing(boolean)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.streaming.api.environment.RemoteStreamEnvironment</code>
<ul>
<li>method removed:
<ul>
<li><code>org.apache.flink.configuration.Configuration getClientConfiguration()</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.streaming.api.environment.StreamExecutionEnvironment</code>
<ul>
<li>field removed:
<ul>
<li><code>java.lang.String DEFAULT_JOB_NAME</code></li>
</ul>
</li>
<li>method removed:
<ul>
<li><code>void addDefaultKryoSerializer(java.lang.Class&lt;?&gt;, com.esotericsoftware.kryo.Serializer&lt;?&gt;)</code></li>
<li><code>void addDefaultKryoSerializer(java.lang.Class&lt;?&gt;, java.lang.Class&lt;? extends com.esotericsoftware.kryo.Serializer&lt;? extends ?&gt;&gt;)</code></li>
<li><code>org.apache.flink.streaming.api.datastream.DataStreamSource&lt;OUT&gt; addSource(org.apache.flink.streaming.api.functions.source.SourceFunction&lt;OUT&gt;)</code></li>
<li><code>org.apache.flink.streaming.api.datastream.DataStreamSource&lt;OUT&gt; addSource(org.apache.flink.streaming.api.functions.source.SourceFunction&lt;OUT&gt;, java.lang.String)</code></li>
<li><code>org.apache.flink.streaming.api.datastream.DataStreamSource&lt;OUT&gt; addSource(org.apache.flink.streaming.api.functions.source.SourceFunction&lt;OUT&gt;, org.apache.flink.api.common.typeinfo.TypeInformation&lt;OUT&gt;)</code></li>
<li><code>org.apache.flink.streaming.api.datastream.DataStreamSource&lt;OUT&gt; addSource(org.apache.flink.streaming.api.functions.source.SourceFunction&lt;OUT&gt;, java.lang.String, org.apache.flink.api.common.typeinfo.TypeInformation&lt;OUT&gt;)</code></li>
<li><code>org.apache.flink.streaming.api.environment.StreamExecutionEnvironment enableCheckpointing(long, org.apache.flink.streaming.api.CheckpointingMode, boolean)</code></li>
<li><code>org.apache.flink.streaming.api.environment.StreamExecutionEnvironment enableCheckpointing()</code></li>
<li><code>int getNumberOfExecutionRetries()</code></li>
<li><code>org.apache.flink.api.common.restartstrategy.RestartStrategies$RestartStrategyConfiguration getRestartStrategy()</code></li>
<li><code>org.apache.flink.runtime.state.StateBackend getStateBackend()</code></li>
<li><code>org.apache.flink.streaming.api.TimeCharacteristic getStreamTimeCharacteristic()</code></li>
<li><code>boolean isForceCheckpointing()</code></li>
<li><code>org.apache.flink.streaming.api.datastream.DataStream&lt;java.lang.String&gt; readFileStream(java.lang.String, long, org.apache.flink.streaming.api.functions.source.FileMonitoringFunction$WatchType)</code></li>
<li><code>org.apache.flink.streaming.api.datastream.DataStreamSource&lt;java.lang.String&gt; readTextFile(java.lang.String)</code></li>
<li><code>org.apache.flink.streaming.api.datastream.DataStreamSource&lt;java.lang.String&gt; readTextFile(java.lang.String, java.lang.String)</code></li>
<li><code>void registerType(java.lang.Class&lt;?&gt;)</code></li>
<li><code>void registerTypeWithKryoSerializer(java.lang.Class&lt;?&gt;, com.esotericsoftware.kryo.Serializer&lt;?&gt;)</code></li>
<li><code>void registerTypeWithKryoSerializer(java.lang.Class&lt;?&gt;, java.lang.Class&lt;? extends com.esotericsoftware.kryo.Serializer&gt;)</code></li>
<li><code>void setNumberOfExecutionRetries(int)</code></li>
<li><code>void setRestartStrategy(org.apache.flink.api.common.restartstrategy.RestartStrategies$RestartStrategyConfiguration)</code></li>
<li><code>org.apache.flink.streaming.api.environment.StreamExecutionEnvironment setStateBackend(org.apache.flink.runtime.state.StateBackend)</code></li>
<li><code>void setStreamTimeCharacteristic(org.apache.flink.streaming.api.TimeCharacteristic)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.streaming.api.operators.AbstractStreamOperator</code>
<ul>
<li>interface removed:
<ul>
<li><code>org.apache.flink.streaming.api.operators.SetupableStreamOperator</code></li>
</ul>
</li>
<li>method modified:
<ul>
<li><code>PROTECTED (&lt;- PUBLIC) void setProcessingTimeService(org.apache.flink.streaming.runtime.tasks.ProcessingTimeService)</code></li>
<li><code>PROTECTED (&lt;- PUBLIC) void setup(org.apache.flink.streaming.runtime.tasks.StreamTask&lt;?,?&gt;&lt;?,?&gt;, org.apache.flink.streaming.api.graph.StreamConfig, org.apache.flink.streaming.api.operators.Output&lt;org.apache.flink.streaming.runtime.streamrecord.StreamRecord&lt;OUT&gt;&gt;&lt;org.apache.flink.streaming.runtime.streamrecord.StreamRecord&lt;OUT&gt;&gt;)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.streaming.api.operators.AbstractUdfStreamOperator</code>
<ul>
<li>method modified:
<ul>
<li><code>PROTECTED (&lt;- PUBLIC) void setup(org.apache.flink.streaming.runtime.tasks.StreamTask&lt;?,?&gt;&lt;?,?&gt;, org.apache.flink.streaming.api.graph.StreamConfig, org.apache.flink.streaming.api.operators.Output&lt;org.apache.flink.streaming.runtime.streamrecord.StreamRecord&lt;OUT&gt;&gt;&lt;org.apache.flink.streaming.runtime.streamrecord.StreamRecord&lt;OUT&gt;&gt;)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.streaming.api.windowing.assigners.EventTimeSessionWindows</code>
<ul>
<li>method removed:
<ul>
<li><code>org.apache.flink.streaming.api.windowing.assigners.EventTimeSessionWindows withGap(org.apache.flink.streaming.api.windowing.time.Time)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.streaming.api.windowing.assigners.ProcessingTimeSessionWindows</code>
<ul>
<li>method removed:
<ul>
<li><code>org.apache.flink.streaming.api.windowing.assigners.ProcessingTimeSessionWindows withGap(org.apache.flink.streaming.api.windowing.time.Time)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.streaming.api.windowing.assigners.SlidingEventTimeWindows</code>
<ul>
<li>method removed:
<ul>
<li><code>org.apache.flink.streaming.api.windowing.assigners.SlidingEventTimeWindows of(org.apache.flink.streaming.api.windowing.time.Time, org.apache.flink.streaming.api.windowing.time.Time)</code></li>
<li><code>org.apache.flink.streaming.api.windowing.assigners.SlidingEventTimeWindows of(org.apache.flink.streaming.api.windowing.time.Time, org.apache.flink.streaming.api.windowing.time.Time, org.apache.flink.streaming.api.windowing.time.Time)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.streaming.api.windowing.assigners.SlidingProcessingTimeWindows</code>
<ul>
<li>method removed:
<ul>
<li><code>org.apache.flink.streaming.api.windowing.assigners.SlidingProcessingTimeWindows of(org.apache.flink.streaming.api.windowing.time.Time, org.apache.flink.streaming.api.windowing.time.Time)</code></li>
<li><code>org.apache.flink.streaming.api.windowing.assigners.SlidingProcessingTimeWindows of(org.apache.flink.streaming.api.windowing.time.Time, org.apache.flink.streaming.api.windowing.time.Time, org.apache.flink.streaming.api.windowing.time.Time)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.streaming.api.windowing.assigners.TumblingEventTimeWindows</code>
<ul>
<li>method removed:
<ul>
<li><code>org.apache.flink.streaming.api.windowing.assigners.TumblingEventTimeWindows of(org.apache.flink.streaming.api.windowing.time.Time)</code></li>
<li><code>org.apache.flink.streaming.api.windowing.assigners.TumblingEventTimeWindows of(org.apache.flink.streaming.api.windowing.time.Time, org.apache.flink.streaming.api.windowing.time.Time)</code></li>
<li><code>org.apache.flink.streaming.api.windowing.assigners.TumblingEventTimeWindows of(org.apache.flink.streaming.api.windowing.time.Time, org.apache.flink.streaming.api.windowing.time.Time, org.apache.flink.streaming.api.windowing.assigners.WindowStagger)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.streaming.api.windowing.assigners.TumblingProcessingTimeWindows</code>
<ul>
<li>method removed:
<ul>
<li><code>org.apache.flink.streaming.api.windowing.assigners.TumblingProcessingTimeWindows of(org.apache.flink.streaming.api.windowing.time.Time)</code></li>
<li><code>org.apache.flink.streaming.api.windowing.assigners.TumblingProcessingTimeWindows of(org.apache.flink.streaming.api.windowing.time.Time, org.apache.flink.streaming.api.windowing.time.Time)</code></li>
<li><code>org.apache.flink.streaming.api.windowing.assigners.TumblingProcessingTimeWindows of(org.apache.flink.streaming.api.windowing.time.Time, org.apache.flink.streaming.api.windowing.time.Time, org.apache.flink.streaming.api.windowing.assigners.WindowStagger)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.streaming.api.windowing.assigners.WindowAssigner</code>
<ul>
<li>method modified:
<ul>
<li><code>(&lt;- NON_ABSTRACT) org.apache.flink.streaming.api.windowing.triggers.Trigger&lt;T,W&gt;&lt;T,W&gt; getDefaultTrigger()</code></li>
</ul>
</li>
<li>method removed:
<ul>
<li><code>org.apache.flink.streaming.api.windowing.triggers.Trigger&lt;T,W&gt; getDefaultTrigger(org.apache.flink.streaming.api.environment.StreamExecutionEnvironment)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.streaming.api.windowing.evictors.TimeEvictor</code>
<ul>
<li>method removed:
<ul>
<li><code>org.apache.flink.streaming.api.windowing.evictors.TimeEvictor&lt;W&gt; of(org.apache.flink.streaming.api.windowing.time.Time)</code></li>
<li><code>org.apache.flink.streaming.api.windowing.evictors.TimeEvictor&lt;W&gt; of(org.apache.flink.streaming.api.windowing.time.Time, boolean)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.streaming.api.windowing.triggers.ContinuousEventTimeTrigger</code>
<ul>
<li>method removed:
<ul>
<li><code>org.apache.flink.streaming.api.windowing.triggers.ContinuousEventTimeTrigger&lt;W&gt; of(org.apache.flink.streaming.api.windowing.time.Time)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.streaming.api.windowing.triggers.ContinuousProcessingTimeTrigger</code>
<ul>
<li>method removed:
<ul>
<li><code>org.apache.flink.streaming.api.windowing.triggers.ContinuousProcessingTimeTrigger&lt;W&gt; of(org.apache.flink.streaming.api.windowing.time.Time)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.streaming.api.windowing.triggers.Trigger$TriggerContext</code>
<ul>
<li>method removed:
<ul>
<li><code>org.apache.flink.api.common.state.ValueState&lt;S&gt; getKeyValueState(java.lang.String, java.lang.Class&lt;S&gt;, java.io.Serializable)</code></li>
<li><code>org.apache.flink.api.common.state.ValueState&lt;S&gt; getKeyValueState(java.lang.String, org.apache.flink.api.common.typeinfo.TypeInformation&lt;S&gt;, java.io.Serializable)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.streaming.experimental.CollectSink</code>
<ul>
<li>interface removed:
<ul>
<li><code>org.apache.flink.streaming.api.functions.sink.SinkFunction</code></li>
</ul>
</li>
<li>superclass modified:
<ul>
<li><code>org.apache.flink.streaming.api.functions.sink.legacy.RichSinkFunction (&lt;- org.apache.flink.streaming.api.functions.sink.RichSinkFunction)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.types.DoubleValue</code>
<ul>
<li>interface removed:
<ul>
<li><code>org.apache.flink.types.Key</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.types.FloatValue</code>
<ul>
<li>interface removed:
<ul>
<li><code>org.apache.flink.types.Key</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.types.NormalizableKey</code>
<ul>
<li>interface removed:
<ul>
<li><code>org.apache.flink.core.io.IOReadableWritable</code></li>
<li><code>org.apache.flink.types.Value</code></li>
<li><code>org.apache.flink.types.Key</code></li>
<li><code>java.io.Serializable</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.test.junit5.MiniClusterExtension</code>
<ul>
<li>method removed:
<ul>
<li><code>org.apache.flink.test.util.TestEnvironment getTestEnvironment()</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.metrics.prometheus.PrometheusPushGatewayReporterOptions</code>
<ul>
<li>field removed:
<ul>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.Integer&gt; PORT</code></li>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.String&gt; HOST</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.formats.csv.CsvReaderFormat</code>
<ul>
<li>method removed:
<ul>
<li><code>org.apache.flink.formats.csv.CsvReaderFormat&lt;T&gt; forSchema(org.apache.flink.shaded.jackson2.com.fasterxml.jackson.dataformat.csv.CsvMapper, org.apache.flink.shaded.jackson2.com.fasterxml.jackson.dataformat.csv.CsvSchema, org.apache.flink.api.common.typeinfo.TypeInformation&lt;T&gt;)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.state.forst.ForStOptionsFactory</code>
<ul>
<li>method removed:
<ul>
<li><code>org.rocksdb.ColumnFamilyOptions createColumnOptions(org.rocksdb.ColumnFamilyOptions, java.util.Collection&lt;java.lang.AutoCloseable&gt;)</code></li>
<li><code>org.rocksdb.DBOptions createDBOptions(org.rocksdb.DBOptions, java.util.Collection&lt;java.lang.AutoCloseable&gt;)</code></li>
<li><code>org.rocksdb.ReadOptions createReadOptions(org.rocksdb.ReadOptions, java.util.Collection&lt;java.lang.AutoCloseable&gt;)</code></li>
<li><code>org.rocksdb.WriteOptions createWriteOptions(org.rocksdb.WriteOptions, java.util.Collection&lt;java.lang.AutoCloseable&gt;)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.state.forst.fs.ForStFlinkFileSystem</code>
<ul>
<li>constructor removed:
<ul>
<li><code>ForStFlinkFileSystem(org.apache.flink.core.fs.FileSystem)</code></li>
</ul>
</li>
<li>method removed:
<ul>
<li><code>org.apache.flink.core.fs.FileSystemKind getKind()</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.table.client.config.SqlClientOptions</code>
<ul>
<li>field removed:
<ul>
<li><code>org.apache.flink.configuration.ConfigOption&lt;java.lang.Integer&gt; DISPLAY_MAX_COLUMN_WIDTH</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.table.runtime.typeutils.SortedMapTypeInfo</code>
<ul>
<li>method removed:
<ul>
<li><code>org.apache.flink.api.common.typeutils.TypeSerializer&lt;java.util.SortedMap&lt;K,V&gt;&gt; createSerializer(org.apache.flink.api.common.ExecutionConfig)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.connector.file.sink.FileSink</code>
<ul>
<li>method removed:
<ul>
<li><code>org.apache.flink.api.connector.sink2.SinkWriter&lt;IN&gt; createWriter(org.apache.flink.api.connector.sink2.Sink$InitContext)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.connector.file.src.FileSource</code>
<ul>
<li>method removed:
<ul>
<li><code>org.apache.flink.connector.file.src.FileSource$FileSourceBuilder&lt;T&gt; forRecordFileFormat(org.apache.flink.connector.file.src.reader.FileRecordFormat&lt;T&gt;, org.apache.flink.core.fs.Path[])</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.connector.file.src.FileSourceSplit</code>
<ul>
<li>constructor removed:
<ul>
<li><code>FileSourceSplit(java.lang.String, org.apache.flink.core.fs.Path, long, long)</code></li>
<li><code>FileSourceSplit(java.lang.String, org.apache.flink.core.fs.Path, long, long, java.lang.String[])</code></li>
<li><code>FileSourceSplit(java.lang.String, org.apache.flink.core.fs.Path, long, long, java.lang.String[], org.apache.flink.connector.file.src.util.CheckpointedPosition)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.state.api.functions.KeyedStateReaderFunction</code>
<ul>
<li>method removed:
<ul>
<li><code>void open(org.apache.flink.configuration.Configuration)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.state.api.OperatorTransformation</code>
<ul>
<li>method removed:
<ul>
<li><code>org.apache.flink.state.api.OneInputOperatorTransformation&lt;T&gt; bootstrapWith(org.apache.flink.api.java.DataSet&lt;T&gt;)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.state.api.SavepointReader</code>
<ul>
<li>method removed:
<ul>
<li><code>org.apache.flink.streaming.api.datastream.DataStream&lt;org.apache.flink.api.java.tuple.Tuple2&lt;K,V&gt;&gt; readBroadcastState(java.lang.String, java.lang.String, org.apache.flink.api.common.typeinfo.TypeInformation&lt;K&gt;, org.apache.flink.api.common.typeinfo.TypeInformation&lt;V&gt;)</code></li>
<li><code>org.apache.flink.streaming.api.datastream.DataStream&lt;org.apache.flink.api.java.tuple.Tuple2&lt;K,V&gt;&gt; readBroadcastState(java.lang.String, java.lang.String, org.apache.flink.api.common.typeinfo.TypeInformation&lt;K&gt;, org.apache.flink.api.common.typeinfo.TypeInformation&lt;V&gt;, org.apache.flink.api.common.typeutils.TypeSerializer&lt;K&gt;, org.apache.flink.api.common.typeutils.TypeSerializer&lt;V&gt;)</code></li>
<li><code>org.apache.flink.streaming.api.datastream.DataStream&lt;OUT&gt; readKeyedState(java.lang.String, org.apache.flink.state.api.functions.KeyedStateReaderFunction&lt;K,OUT&gt;)</code></li>
<li><code>org.apache.flink.streaming.api.datastream.DataStream&lt;OUT&gt; readKeyedState(java.lang.String, org.apache.flink.state.api.functions.KeyedStateReaderFunction&lt;K,OUT&gt;, org.apache.flink.api.common.typeinfo.TypeInformation&lt;K&gt;, org.apache.flink.api.common.typeinfo.TypeInformation&lt;OUT&gt;)</code></li>
<li><code>org.apache.flink.streaming.api.datastream.DataStream&lt;T&gt; readListState(java.lang.String, java.lang.String, org.apache.flink.api.common.typeinfo.TypeInformation&lt;T&gt;)</code></li>
<li><code>org.apache.flink.streaming.api.datastream.DataStream&lt;T&gt; readListState(java.lang.String, java.lang.String, org.apache.flink.api.common.typeinfo.TypeInformation&lt;T&gt;, org.apache.flink.api.common.typeutils.TypeSerializer&lt;T&gt;)</code></li>
<li><code>org.apache.flink.streaming.api.datastream.DataStream&lt;T&gt; readUnionState(java.lang.String, java.lang.String, org.apache.flink.api.common.typeinfo.TypeInformation&lt;T&gt;)</code></li>
<li><code>org.apache.flink.streaming.api.datastream.DataStream&lt;T&gt; readUnionState(java.lang.String, java.lang.String, org.apache.flink.api.common.typeinfo.TypeInformation&lt;T&gt;, org.apache.flink.api.common.typeutils.TypeSerializer&lt;T&gt;)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.state.api.SavepointWriter</code>
<ul>
<li>method removed:
<ul>
<li><code>org.apache.flink.state.api.SavepointWriter fromExistingSavepoint(java.lang.String)</code></li>
<li><code>org.apache.flink.state.api.SavepointWriter fromExistingSavepoint(java.lang.String, org.apache.flink.runtime.state.StateBackend)</code></li>
<li><code>org.apache.flink.state.api.SavepointWriter newSavepoint(int)</code></li>
<li><code>org.apache.flink.state.api.SavepointWriter newSavepoint(org.apache.flink.runtime.state.StateBackend, int)</code></li>
<li><code>org.apache.flink.state.api.SavepointWriter removeOperator(java.lang.String)</code></li>
<li><code>org.apache.flink.state.api.SavepointWriter withOperator(java.lang.String, org.apache.flink.state.api.StateBootstrapTransformation&lt;T&gt;)</code></li>
</ul>
</li>
</ul>
</li>
<li><code>org.apache.flink.state.api.SavepointWriterOperatorFactory</code>
<ul>
<li>method modified:
<ul>
<li><code>org.apache.flink.streaming.api.operators.StreamOperatorFactory&lt;org.apache.flink.state.api.output.TaggedOperatorSubtaskState&gt;&lt;org.apache.flink.state.api.output.TaggedOperatorSubtaskState&gt; (&lt;-org.apache.flink.streaming.api.operators.StreamOperator&lt;org.apache.flink.state.api.output.TaggedOperatorSubtaskState&gt;&lt;org.apache.flink.state.api.output.TaggedOperatorSubtaskState&gt;) createOperator(long, org.apache.flink.core.fs.Path)</code></li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="list-of-removed-configuration-options-a-nameremoved_configs-">
  List of removed configuration options <a name="removed_configs" />
  <a class="anchor" href="#list-of-removed-configuration-options-a-nameremoved_configs-">#</a>
</h2>
<ul>
<li>cluster.evenly-spread-out-slots</li>
<li>fine-grained.shuffle-mode.all-blocking</li>
<li>high-availability.job.delay</li>
<li>high-availability.zookeeper.path.running-registry</li>
<li>jobmanager.adaptive-batch-scheduler.avg-data-volume-per-task</li>
<li>jobmanager.adaptive-batch-scheduler.default-source-parallelism</li>
<li>jobmanager.adaptive-batch-scheduler.max-parallelism</li>
<li>jobmanager.adaptive-batch-scheduler.min-parallelism</li>
<li>jobmanager.adaptive-batch-scheduler.speculative.block-slow-node-duration</li>
<li>jobmanager.adaptive-batch-scheduler.speculative.enabled</li>
<li>jobmanager.adaptive-batch-scheduler.speculative.max-concurrent-executions</li>
<li>jobmanager.heap.mb</li>
<li>jobmanager.heap.size</li>
<li>jobmanager.web.backpressure.cleanup-interval</li>
<li>jobmanager.web.backpressure.delay-between-samples</li>
<li>jobmanager.web.backpressure.num-samples</li>
<li>jobmanager.web.backpressure.refresh-interval</li>
<li>jobmanager.web.ssl.enabled</li>
<li>local.number-resourcemanager</li>
<li>pipeline.auto-type-registration</li>
<li>pipeline.default-kryo-serializers</li>
<li>pipeline.registered-kryo-types</li>
<li>pipeline.registered-pojo-types</li>
<li>recovery.job.delay</li>
<li>resourcemanager.taskmanager-release.wait.result.consumed</li>
<li>security.kerberos.fetch.delegation-token</li>
<li>security.kerberos.tokens.renewal.retry.backoff</li>
<li>security.kerberos.tokens.renewal.time-ratio</li>
<li>security.ssl.enabled</li>
<li>slotmanager.taskmanager-timeout</li>
<li>sql-client.display.max-column-width</li>
<li>state.backend.async</li>
<li>state.backend.latency-track.history-size</li>
<li>state.backend.latency-track.keyed-state-enabled</li>
<li>state.backend.latency-track.sample-interval</li>
<li>state.backend.latency-track.state-name-as-variable</li>
<li>state.backend.local-recovery</li>
<li>state.backend.rocksdb.checkpointdir</li>
<li>state.backend.type</li>
<li>streaming-source.consume-order</li>
<li>table.exec.deduplicate.insert-and-updateafter-sensitive.enabled</li>
<li>table.exec.deduplicate.mini-batch.compact-changes.enabled</li>
<li>table.exec.legacy-transformation-uids</li>
<li>table.exec.shuffle-mode</li>
<li>table.exec.topn-cache-size</li>
<li>table.optimizer.source.aggregate-pushdown-enabled</li>
<li>table.optimizer.source.predicate-pushdown-enabled</li>
<li>table.optimizer.sql-to-rel.project.merge.enabled</li>
<li>taskmanager.exit-on-fatal-akka-error</li>
<li>taskmanager.heap.mb</li>
<li>taskmanager.heap.size</li>
<li>taskmanager.initial-registration-pause</li>
<li>taskmanager.max-registration-pause</li>
<li>taskmanager.net.client.numThreads</li>
<li>taskmanager.net.num-arenas</li>
<li>taskmanager.net.sendReceiveBufferSize</li>
<li>taskmanager.net.server.backlog</li>
<li>taskmanager.net.server.numThreads</li>
<li>taskmanager.net.transport</li>
<li>taskmanager.network.batch-shuffle.compression.enabled</li>
<li>taskmanager.network.blocking-shuffle.compression.enabled</li>
<li>taskmanager.network.blocking-shuffle.type</li>
<li>taskmanager.network.hybrid-shuffle.enable-new-mode</li>
<li>taskmanager.network.hybrid-shuffle.num-retained-in-memory-regions-max</li>
<li>taskmanager.network.hybrid-shuffle.spill-index-region-group-size</li>
<li>taskmanager.network.hybrid-shuffle.spill-index-segment-size</li>
<li>taskmanager.network.max-num-tcp-connections</li>
<li>taskmanager.network.memory.buffers-per-channel</li>
<li>taskmanager.network.memory.exclusive-buffers-request-timeout-ms</li>
<li>taskmanager.network.memory.floating-buffers-per-gate</li>
<li>taskmanager.network.memory.fraction</li>
<li>taskmanager.network.memory.max</li>
<li>taskmanager.network.memory.max-buffers-per-channel</li>
<li>taskmanager.network.memory.max-overdraft-buffers-per-gate</li>
<li>taskmanager.network.memory.min</li>
<li>taskmanager.network.netty.client.numThreads</li>
<li>taskmanager.network.netty.num-arenas</li>
<li>taskmanager.network.netty.sendReceiveBufferSize</li>
<li>taskmanager.network.netty.server.backlog</li>
<li>taskmanager.network.netty.server.numThreads</li>
<li>taskmanager.network.netty.transport</li>
<li>taskmanager.network.numberOfBuffers</li>
<li>taskmanager.network.sort-shuffle.min-parallelism</li>
<li>taskmanager.refused-registration-pause</li>
<li>taskmanager.registration.initial-backoff</li>
<li>taskmanager.registration.max-backoff</li>
<li>taskmanager.registration.refused-backoff</li>
<li>web.address</li>
<li>web.backpressure.cleanup-interval</li>
<li>web.backpressure.delay-between-samples</li>
<li>web.backpressure.num-samples</li>
<li>web.backpressure.refresh-interval</li>
<li>web.port</li>
<li>web.ssl.enabled</li>
</ul>
<h2 id="list-of-rest-apis-changes-a-namebreaking_rest_apis">
  List of REST APIs changes <a name="breaking_rest_apis">
  <a class="anchor" href="#list-of-rest-apis-changes-a-namebreaking_rest_apis">#</a>
</h2>
<table>
<thead>
<tr>
<th>REST API</th>
<th>Changes</th>
</tr>
</thead>
<tbody>
<tr>
<td>/taskmanagers/:taskmanagerid</td>
<td>In its response, &ldquo;metrics.memorySegmentsAvailable&rdquo; and &ldquo;metrics.memorySegmentsTotal&rdquo; are removed.</td>
</tr>
<tr>
<td>/jobs/:jobid/config</td>
<td>In its response, the &ldquo;execution-mode&rdquo; property is removed.</td>
</tr>
<tr>
<td>/jars/:jarid/run</td>
<td>In its request, the internal type of &ldquo;claimMode&rdquo; and &ldquo;restoreMode&rdquo; are changed from RestoreMode to RecoveryClaimMode, but their json structure is not affected.</td>
</tr>
<tr>
<td>/jobs/:jobid/vertices/:vertexid<br />/jobs/:jobid/vertices/:vertexid/subtasks/accumulators<br />/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex<br />/jobs/:jobid/vertices/:vertexid/subtasks/:subtaskindex/attempts/:attempt<br />/jobs/:jobid/vertices/:vertexid/subtasktimes<br />/jobs/:jobid/vertices/:vertexid/taskmanagers<br />/jobs/:jobid/taskmanagers/:taskmanagerid/log-url</td>
<td>In their responses, the &ldquo;host&rdquo;, &ldquo;subtasks.host&rdquo; or &ldquo;taskmanagers.host&rdquo; property is removed.</td>
</tr>
</tbody>
</table>
<h2 id="list-of-removed-cli-options-a-nameremoved_cli_options-">
  List of removed CLI options <a name="removed_cli_options" />
  <a class="anchor" href="#list-of-removed-cli-options-a-nameremoved_cli_options-">#</a>
</h2>
<ul>
<li>sql-client.sh:
<ul>
<li><code>-u,--update &lt;SQL update statement&gt;</code> is removed</li>
</ul>
</li>
<li>flink-client:
<ul>
<li><code>run-application</code> action is removed: Please use <code>run -t kubernetes-application</code> to run Kubernetes Application mode</li>
</ul>
</li>
</ul>
</p>
</article>

          



  
    
    <div class="edit-this-page">
      <p>
        <a href="https://cwiki.apache.org/confluence/display/FLINK/Flink+Translation+Specifications">Want to contribute translation?</a>
      </p>
      <p>
        <a href="//github.com/apache/flink-web/edit/asf-site/docs/content/posts/2024-10-23-release-2.0-preview.md">
          Edit This Page<i class="fa fa-edit fa-fw"></i> 
        </a>
      </p>
    </div>

        </section>
        
          <aside class="book-toc">
            


<nav id="TableOfContents"><h3>On This Page <a href="javascript:void(0)" class="toc" onclick="collapseToc()"><i class="fa fa-times" aria-hidden="true"></i></a></h3>
  <ul>
    <li><a href="#breaking-changes">Breaking Changes</a>
      <ul>
        <li><a href="#api">API</a>
          <ul>
            <li><a href="#connector-adaption-plan">Connector Adaption Plan</a></li>
          </ul>
        </li>
        <li><a href="#configuration">Configuration</a></li>
        <li><a href="#misc">Misc</a></li>
      </ul>
    </li>
    <li><a href="#highlights-of-new-features">Highlights of New Features</a>
      <ul>
        <li><a href="#disaggregated-state-storage-and-management">Disaggregated State Storage and Management</a></li>
        <li><a href="#materialized-table">Materialized Table</a></li>
        <li><a href="#adaptive-batch-execution">Adaptive Batch Execution</a></li>
        <li><a href="#streaming-lakehouse">Streaming Lakehouse</a></li>
      </ul>
    </li>
    <li><a href="#appendix">Appendix</a>
      <ul>
        <li><a href="#list-of-breaking-change-programming-apis-a-namebreaking_programming_apis-">List of breaking change programming APIs <a name="breaking_programming_apis" /></a>
          <ul>
            <li><a href="#removed-classes">Removed Classes</a></li>
            <li><a href="#modified-classes">Modified Classes</a></li>
          </ul>
        </li>
        <li><a href="#list-of-removed-configuration-options-a-nameremoved_configs-">List of removed configuration options <a name="removed_configs" /></a></li>
        <li><a href="#list-of-rest-apis-changes-a-namebreaking_rest_apis">List of REST APIs changes <a name="breaking_rest_apis"></a></li>
        <li><a href="#list-of-removed-cli-options-a-nameremoved_cli_options-">List of removed CLI options <a name="removed_cli_options" /></a></li>
      </ul>
    </li>
  </ul>
</nav>


          </aside>
          <aside class="expand-toc hidden">
            <a class="toc" onclick="expandToc()" href="javascript:void(0)">
              <i class="fa fa-bars" aria-hidden="true"></i>
            </a>
          </aside>
        
      </main>

      <footer>
        


<div class="separator"></div>
<div class="panels">
  <div class="wrapper">
      <div class="panel">
        <ul>
          <li>
            <a href="https://flink-packages.org/">flink-packages.org</a>
          </li>
          <li>
            <a href="https://www.apache.org/">Apache Software Foundation</a>
          </li>
          <li>
            <a href="https://www.apache.org/licenses/">License</a>
          </li>
          
          
          
            
          
            
          
          

          
            
              
            
          
            
              
                <li>
                  <a  href="/zh/">
                    <i class="fa fa-globe" aria-hidden="true"></i>&nbsp;
                  </a>
                </li>
              
            
          
       </ul>
      </div>
      <div class="panel">
        <ul>
          <li>
            <a href="/what-is-flink/security">Security</a-->
          </li>
          <li>
            <a href="https://www.apache.org/foundation/sponsorship.html">Donate</a>
          </li>
          <li>
            <a href="https://www.apache.org/foundation/thanks.html">Thanks</a>
          </li>
       </ul>
      </div>
      <div class="panel icons">
        <div>
          <a href="/posts">
            <div class="icon flink-blog-icon"></div>
            <span>Flink blog</span>
          </a>
        </div>
        <div>
          <a href="https://github.com/apache/flink">
            <div class="icon flink-github-icon"></div>
            <span>Github</span>
          </a>
        </div>
        <div>
          <a href="https://twitter.com/apacheflink">
            <div class="icon flink-twitter-icon"></div>
            <span>Twitter</span>
          </a>
        </div>
      </div>
  </div>
</div>

<hr/>

<div class="container disclaimer">
  <p>The contents of this website are  2024 Apache Software Foundation under the terms of the Apache License v2. Apache Flink, Flink, and the Flink logo are either registered trademarks or trademarks of The Apache Software Foundation in the United States and other countries.</p>
</div>



      </footer>
    
  </body>
</html>






